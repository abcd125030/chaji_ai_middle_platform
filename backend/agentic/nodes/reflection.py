"""
åæ€è¯„ä¼°èŠ‚ç‚¹
è´Ÿè´£è¯„ä¼°å·¥å…·æ‰§è¡Œç»“æœæ˜¯å¦è¾¾åˆ°é¢„æœŸï¼Œç”Ÿæˆåæ€ç»“è®º
"""
import json
import logging
from typing import Dict, Any, Optional
from datetime import datetime, timedelta

from ..core.schemas import RuntimeState, PlannerOutput, ReflectionOutput
from llm.core_service import CoreLLMService
from llm.config_manager import ModelConfigManager
from .components import safe_json_dumps
from ..utils.logger_config import logger, log_llm_request, log_llm_response, log_state_change

# ä¸ºäº†ä¿æŒå‘åå…¼å®¹
_safe_json_dumps = safe_json_dumps


def _format_metrics(metrics):
    """æ ¼å¼åŒ– metrics ä¸ºå¯è¯»å­—ç¬¦ä¸²"""
    if not metrics:
        return "æ— å…³é”®æŒ‡æ ‡"
    
    if isinstance(metrics, list):
        # æ–°æ ¼å¼ï¼šåˆ—è¡¨å½¢å¼çš„ metrics
        if not metrics:
            return "æ— å…³é”®æŒ‡æ ‡"
        return "\n".join(f"- {metric}" for metric in metrics)
    elif isinstance(metrics, dict):
        # æ—§æ ¼å¼ï¼šå­—å…¸å½¢å¼çš„ metrics
        if not metrics:
            return "æ— å…³é”®æŒ‡æ ‡"
        return "\n".join(f"- {key}: {value}" for key, value in metrics.items())
    else:
        return str(metrics)


def reflection_node(state: RuntimeState, nodes_map: Optional[Dict[str, Any]] = None, 
                   edges_map: Optional[Dict[str, Any]] = None, 
                   current_plan: Optional[PlannerOutput] = None,
                   current_tool_output: Optional[Dict[str, Any]] = None,
                   user=None, session_id: Optional[str] = None) -> Dict[str, Any]:
    """
    åæ€å™¨èŠ‚ç‚¹å‡½æ•°ã€‚
    è¯„ä¼°ä¸Šä¸€æ¬¡å·¥å…·æ‰§è¡Œçš„ç»“æœæ˜¯å¦è¾¾åˆ°äº†é¢„æœŸã€‚å®ƒä¼šç”Ÿæˆä¸€ä¸ªåŒ…å«ç»“è®ºå’ŒæˆåŠŸçŠ¶æ€çš„åæ€ç»“æœã€‚
    æ­¤èŠ‚ç‚¹é€šå¸¸åœ¨å·¥å…·æ‰§è¡Œå™¨ï¼ˆtool_executorï¼‰ä¹‹åè¢«è°ƒç”¨ã€‚

    å‚æ•°:
    state (RuntimeState): å½“å‰çš„è¿è¡Œæ—¶çŠ¶æ€ã€‚
    nodes_map (Optional[Dict[str, Any]]): åŒ…å«å›¾ä¸­æ‰€æœ‰èŠ‚ç‚¹çš„å­—å…¸ï¼Œç”¨äºè·å–èŠ‚ç‚¹é…ç½®ã€‚
    edges_map (Optional[Dict[str, Any]]): åŒ…å«å›¾ä¸­æ‰€æœ‰è¾¹çš„å­—å…¸ï¼ˆåœ¨æ­¤èŠ‚ç‚¹ä¸­æœªä½¿ç”¨ï¼Œä½†ä¸ºäº†æ¥å£ä¸€è‡´æ€§ä¿ç•™ï¼‰ã€‚
    current_plan (Optional[PlannerOutput]): å½“å‰çš„æ‰§è¡Œè®¡åˆ’ã€‚
    current_tool_output (Optional[Dict[str, Any]]): å½“å‰å·¥å…·çš„è¾“å‡ºç»“æœã€‚
    user: ç”¨æˆ·å¯¹è±¡ï¼ˆç”¨äºæ—¥å¿—è®°å½•ï¼‰
    session_id (Optional[str]): ä¼šè¯IDï¼ˆç”¨äºæ—¥å¿—è®°å½•ï¼‰

    è¿”å›:
    Dict[str, Any]: åŒ…å«æ›´æ–°åçš„è¡ŒåŠ¨å†å²çš„å­—å…¸ï¼Œé”®ä¸º"action_history"ã€‚
    """
    
    # å®ä¾‹åŒ–æ ¸å¿ƒLLMæœåŠ¡å’Œé…ç½®ç®¡ç†å™¨
    core_service = CoreLLMService()
    config_manager = ModelConfigManager()
    
    # ä½¿ç”¨ç»Ÿä¸€çš„æ¨¡å‹é…ç½®æœåŠ¡è·å–æ¨¡å‹åç§°
    from agentic.core.model_config_service import NodeModelConfigService
    model_name = NodeModelConfigService.get_model_for_node('reflection', nodes_map)
    
    # è·å–æ¨¡å‹é…ç½®ï¼ˆå·²åŒ…å«vendor_nameï¼‰
    model_config = config_manager.get_model_config(model_name)
    
    # è·å–ä¸€ä¸ªç»“æ„åŒ–è¾“å‡ºçš„LLMå®ä¾‹ï¼Œå…¶è¾“å‡ºå°†ä¸¥æ ¼ç¬¦åˆReflectionOutput Pydanticæ¨¡å‹
    structured_llm = core_service.get_structured_llm(
        ReflectionOutput, 
        model_config,
        user=user,
        session_id=session_id,
        model_name=model_name,
        source_app='agentic',
        source_function='nodes.reflection.reflection_node'
    ) # åæ€å¯ä»¥ä½¿ç”¨æ›´å¿«çš„LLM
    
    # ç¡®ä¿ current_plan å’Œ current_tool_output å­˜åœ¨ï¼Œè¿™æ˜¯åæ€èŠ‚ç‚¹è¿è¡Œçš„å‰æ
    if not current_plan or current_tool_output is None:
        # è¿™åº”è¯¥æ˜¯ä¸€ä¸ªå¼‚å¸¸æƒ…å†µï¼Œå› ä¸º reflection èŠ‚ç‚¹æ€»æ˜¯åœ¨ tool_executor ä¹‹åè¢«è°ƒç”¨ï¼Œæ­¤æ—¶è¿™äº›æ•°æ®åº”å·²å­˜åœ¨
        raise ValueError("Reflection node called without current_plan or current_tool_output.")

    # ä»å·¥å…·è¾“å‡ºä¸­æå–å…³é”®ä¿¡æ¯ï¼ˆä¼˜å…ˆä½¿ç”¨ç»Ÿä¸€è¾“å‡ºæ ¼å¼ï¼‰
    tool_status = current_tool_output.get("status", "unknown")
    tool_message = current_tool_output.get("message", "")
    
    # ä¼˜å…ˆä½¿ç”¨æ–°çš„ç»Ÿä¸€æ ¼å¼
    if "output" in current_tool_output and "type" in current_tool_output:
        # æ–°æ ¼å¼ï¼šç›´æ¥ä½¿ç”¨ output ä½œä¸ºä¸»è¦ç»“æœ
        primary_result = current_tool_output.get("output")
        output_type = current_tool_output.get("type", "text")
        key_metrics = current_tool_output.get("metrics", [])  # æ–°æ ¼å¼æ˜¯åˆ—è¡¨
        raw_data = current_tool_output.get("raw_data", {})
    else:
        # å…¼å®¹æ—§æ ¼å¼
        key_metrics = current_tool_output.get("key_metrics", {})
        raw_data = current_tool_output.get("raw_data", {})
        
        # ä» raw_data ä¸­æå–ä¸»è¦ç»“æœï¼ˆé€‚é…æ—§æ ¼å¼ï¼‰
        if isinstance(raw_data, dict) and "text" in raw_data:
            primary_result = raw_data.get("text")
        elif isinstance(raw_data, dict):
            primary_result = raw_data.get("data", raw_data)
        else:
            primary_result = raw_data
        
        # å†æ¬¡å…¼å®¹ï¼šç›´æ¥ä» data å­—æ®µæå–
        if primary_result is None and "data" in current_tool_output:
            primary_result = current_tool_output["data"]
        
        output_type = "text"  # æ—§æ ¼å¼é»˜è®¤ä¸ºæ–‡æœ¬
    
    # è·å–æœŸæœ›ç»“æœï¼ˆå¦‚æœ planner æä¾›äº†ï¼‰
    expected_outcome = current_plan.expected_outcome if hasattr(current_plan, 'expected_outcome') and current_plan.expected_outcome else "æœªæ˜ç¡®æŒ‡å®šå…·ä½“æœŸæœ›ç»“æœï¼Œéœ€è¦æ ¹æ®å·¥å…·çš„å®é™…è¾“å‡ºè¿›è¡Œè¯„ä¼°"
    
    # æ„å»ºç³»ç»Ÿæç¤ºè¯ï¼ˆåŒ…å«åæ€è§„åˆ™å’ŒæŒ‡å¯¼ï¼‰
    system_prompt = """# åæ€è¯„ä¼°è€…

ä½ æ˜¯ä¸€ä¸ªè´Ÿè´£è¯„ä¼°å·¥å…·æ‰§è¡Œç»“æœçš„åæ€èŠ‚ç‚¹ã€‚ä½ çš„ä»»åŠ¡æ˜¯ä¸¥æ ¼è¯„ä¼°æ¯ä¸€æ­¥æ“ä½œçš„æ‰§è¡Œæƒ…å†µå’Œç»“æœè´¨é‡ï¼Œå¹¶ç”Ÿæˆè¯­ä¹‰åŒ–çš„æ‘˜è¦ã€‚

## è¯„ä¼°åŸåˆ™
1. **å®¢è§‚è¯„ä¼°**: åŸºäºå®é™…æ‰§è¡Œç»“æœè¿›è¡Œå®¢è§‚åˆ¤æ–­
2. **ä¸¥æ ¼æ ‡å‡†**: å¯¹ç»“æœçš„å……åˆ†æ€§ä¿æŒä¸¥æ ¼æ ‡å‡†
3. **æ¸…æ™°æ€»ç»“**: æä¾›ç®€æ˜æ‰¼è¦çš„ç»“è®º
4. **è¯­ä¹‰æ‘˜è¦**: ç”ŸæˆçœŸæ­£ç†è§£å·¥å…·è¾“å‡ºè¯­ä¹‰çš„æ‘˜è¦ï¼Œè€Œéæœºæ¢°æå–

## è¯„ä¼°ç»´åº¦
- **æ‰§è¡ŒçŠ¶æ€**: å·¥å…·æ˜¯å¦æˆåŠŸæ‰§è¡Œï¼ˆæŸ¥çœ‹statuså­—æ®µï¼‰
- **ç»“æœè´¨é‡**: è¾“å‡ºå†…å®¹æ˜¯å¦æœ‰æ„ä¹‰ä¸”å……åˆ†
- **ç›®æ ‡è¾¾æˆ**: æ˜¯å¦è¾¾åˆ°äº†é¢„æœŸç›®æ ‡
- **è¯­ä¹‰ç†è§£**: ç†è§£å·¥å…·å®Œæˆäº†ä»€ä¹ˆä»»åŠ¡ï¼Œè·å¾—äº†ä»€ä¹ˆæ ¸å¿ƒç»“æœ

## è¾“å‡ºè¦æ±‚
ä½ éœ€è¦ç”Ÿæˆä»¥ä¸‹å†…å®¹ï¼š
1. **conclusion**: å¯¹æ‰§è¡Œç»“æœçš„è¯¦ç»†è¯„ä»·ï¼ˆ2-3å¥è¯ï¼‰
2. **summary**: ä¸€å¥è¯è¯­ä¹‰æ‘˜è¦ï¼Œæè¿°"å·¥å…·åšäº†ä»€ä¹ˆï¼Œå¾—åˆ°äº†ä»€ä¹ˆç»“æœ"
   - ç¤ºä¾‹ï¼š"æœç´¢äº†æœ€æ–°AIæŠ€æœ¯è¶‹åŠ¿ï¼Œæ‰¾åˆ°5ç¯‡ç›¸å…³æ–‡ç« å¹¶æ€»ç»“äº†ä¸»è¦è§‚ç‚¹"
   - ç¤ºä¾‹ï¼š"åˆ†æäº†é”€å”®æ•°æ®è¡¨ï¼Œå‘ç°Q4å¢é•¿ç‡è¾¾åˆ°25%"
3. **impact**: è¿™æ¬¡æ‰§è¡Œå¯¹æ•´ä½“ä»»åŠ¡çš„å½±å“å’Œè´¡çŒ®
4. **key_findings**: ä»è¾“å‡ºä¸­æå–çš„3-5ä¸ªå…³é”®å‘ç°ï¼ˆæ¯ä¸ªä¸è¶…è¿‡20å­—ï¼‰
5. **is_finished**: å·¥å…·æ˜¯å¦æˆåŠŸæ‰§è¡Œå®Œæˆ
6. **is_sufficient**: ç»“æœæ˜¯å¦å……åˆ†æ»¡è¶³éœ€æ±‚

## TODOä»»åŠ¡è¯„ä¼°æ ‡å‡†
å¯¹äºtodo_generatorå·¥å…·ï¼Œéœ€è¦è¯„ä¼°ï¼š
- ä»»åŠ¡åˆ†è§£æ˜¯å¦åˆç†å’Œå®Œæ•´
- ä»»åŠ¡æ•°é‡æ˜¯å¦é€‚å½“ï¼ˆé€šå¸¸3-10ä¸ªï¼‰
- æ¯ä¸ªä»»åŠ¡æ˜¯å¦æœ‰æ˜ç¡®çš„ï¼šä»»åŠ¡æè¿°ã€ä¼˜å…ˆçº§ã€é¢„è®¡æ—¶é—´ã€å»ºè®®å·¥å…·ã€æˆåŠŸæ ‡å‡†
- ä»»åŠ¡é—´çš„ä¾èµ–å…³ç³»æ˜¯å¦æ¸…æ™°
- æ•´ä½“ä»»åŠ¡è§„åˆ’æ˜¯å¦èƒ½å¤Ÿè§£å†³ç”¨æˆ·é—®é¢˜

## æ³¨æ„äº‹é¡¹
- é‡ç‚¹å…³æ³¨å·¥å…·çš„å®é™…è¾“å‡ºå†…å®¹ï¼Œç†è§£å…¶è¯­ä¹‰
- summary åº”è¯¥æ˜¯è‡ªç„¶è¯­è¨€æè¿°ï¼Œä¸æ˜¯æœºæ¢°æå–
- key_findings åº”è¯¥æ˜¯å…·ä½“çš„å‘ç°ï¼Œè€Œéæ³›æ³›æè¿°
- å·¥å…·å¯èƒ½ä½¿ç”¨ä¸åŒçš„æ¨¡å‹ï¼Œè¿™ä¸ä½ è‡ªèº«æ— å…³"""

    # æ„å»ºç”¨æˆ·æç¤ºè¯ï¼ˆåŒ…å«å…·ä½“çš„æ‰§è¡Œä¿¡æ¯ï¼‰
    # å·¥å…·æ˜¾ç¤ºä¿¡æ¯
    tool_name_display = current_plan.tool_name
    tool_input_display = _safe_json_dumps(current_plan.tool_input)
    
    user_prompt = f"""## å½“å‰è¯„ä¼°ä»»åŠ¡

### æ‰§è¡Œè®¡åˆ’
**æ€è€ƒè¿‡ç¨‹**: {current_plan.thought}
**è°ƒç”¨å·¥å…·**: {tool_name_display}
**å·¥å…·è¾“å…¥**:
```json
{tool_input_display}
```

### æœŸæœ›ç»“æœ
{expected_outcome}

### å®é™…æ‰§è¡Œç»“æœ
**æ‰§è¡ŒçŠ¶æ€**: {tool_status}
**è¿”å›æ¶ˆæ¯**: {tool_message}
**è¾“å‡ºç±»å‹**: {output_type if 'output_type' in locals() else 'text'}
**ä¸»è¦ç»“æœ**:
```
{_safe_json_dumps(primary_result) if primary_result is not None else "æ— ä¸»è¦ç»“æœ"}
```
**å…³é”®æŒ‡æ ‡**:
{_format_metrics(key_metrics)}

è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ï¼Œè¯„ä¼°è¿™æ¬¡å·¥å…·è°ƒç”¨çš„æ‰§è¡Œæƒ…å†µå’Œç»“æœè´¨é‡ã€‚"""

    # æ‰“å°å®Œæ•´çš„åæ€æç¤ºè¯ï¼ˆç”¨äºè°ƒè¯•ï¼Œå•ä¸ª logger è°ƒç”¨ï¼‰
    reflection_debug_info = f"""
{"=" * 60}
ğŸ” REFLECTION NODE - å®Œæ•´è¯·æ±‚ä¿¡æ¯
{"=" * 60}

ã€System Promptã€‘
{system_prompt}

{"=" * 60}

ã€User Promptã€‘
{user_prompt}

{"=" * 60}
"""
    logger.info(reflection_debug_info)
    
    try:
        # è®°å½•LLMè¯·æ±‚
        log_llm_request("reflection", system_prompt, user_prompt, model_name)
        # è°ƒç”¨LLMè¿›è¡Œåæ€è¯„ä¼°ï¼Œä¼ å…¥ç³»ç»Ÿæç¤ºè¯å’Œç”¨æˆ·æç¤ºè¯
        llm_reflection_result = structured_llm.invoke(user_prompt, system_prompt=system_prompt)
        # è®°å½•LLMå“åº”
        log_llm_response("reflection", llm_reflection_result)
    except Exception as e:
        if "ç»“æ„åŒ–è¾“å‡ºè§£æå¤±è´¥" in str(e):
            llm_reflection_result = structured_llm.invoke(user_prompt, system_prompt=system_prompt) # é‡è¯•ä¸€æ¬¡
        else:
            raise e
    
    # å°† reflection æ·»åŠ åˆ°è¡ŒåŠ¨å†å²ä¸­
    # æ¯ä¸ªæ¡ç›®éƒ½æ˜¯ä¸€ä¸ªå­—å…¸ï¼ŒåŒ…å« 'type' å’Œ 'data'
    reflection_data = None
    action_id = None  # æå‰å£°æ˜ action_id
    
    if llm_reflection_result:
        # æå–æ‰€æœ‰å­—æ®µï¼ŒåŒ…æ‹¬æ–°å¢çš„è¯­ä¹‰æ‘˜è¦å­—æ®µ
        reflection_dict = llm_reflection_result.model_dump()
        # ä¿ç•™æ‰€æœ‰å­—æ®µï¼ŒåŒæ—¶å°†conclusionæ˜ å°„ä¸ºoutputï¼ˆå‘åå…¼å®¹ï¼‰
        reflection_data = {
            "output": reflection_dict.get("conclusion", ""),  # ç»Ÿä¸€ä½¿ç”¨outputå­—æ®µï¼ˆå‘åå…¼å®¹ï¼‰
            "conclusion": reflection_dict.get("conclusion", ""),  # ä¿ç•™åŸå§‹å­—æ®µ
            "summary": reflection_dict.get("summary", ""),  # æ–°å¢ï¼šè¯­ä¹‰æ‘˜è¦
            "impact": reflection_dict.get("impact", ""),  # æ–°å¢ï¼šä»»åŠ¡å½±å“
            "key_findings": reflection_dict.get("key_findings", []),  # æ–°å¢ï¼šå…³é”®å‘ç°
            "is_finished": reflection_dict.get("is_finished", False),
            "is_sufficient": reflection_dict.get("is_sufficient", False),
            # action_id å°†åœ¨ç”Ÿæˆ action_summary åå¡«å……
        }
    
    # å…ˆä¸æ·»åŠ åˆ° action_historyï¼Œç­‰ç”Ÿæˆ action_summary åå†æ·»åŠ ï¼ˆåŒ…å«action_idï¼‰
    
    # å¤„ç†TodoGeneratorçš„è¾“å‡ºï¼Œæ›´æ–°state.todo
    if current_plan and current_plan.tool_name == "TodoGenerator":
        # ä¼˜å…ˆæ£€æŸ¥æ–°æ ¼å¼ï¼šraw_data å­—æ®µ
        if current_tool_output and current_tool_output.get('raw_data'):
            raw_data = current_tool_output['raw_data']
            if isinstance(raw_data, dict) and 'todo_list' in raw_data:
                # TodoGenerator æ–°æ ¼å¼è¾“å‡º
                state.todo = raw_data['todo_list']
                logger.info(f"[REFLECTION] TodoGenerator åˆ›å»ºäº† {len(state.todo)} ä¸ªä»»åŠ¡")
                # åˆå¹¶æ‰€æœ‰TODOä¿¡æ¯åˆ°ä¸€ä¸ªæ—¥å¿—æ¡ç›®
                todo_list_str = "========== TodoGeneratoråˆ›å»ºTODOæ¸…å• ==========\n"
                for idx, task in enumerate(state.todo, 1):
                    task_id = task.get('id', '?')
                    task_desc = task.get('task', 'æœªçŸ¥ä»»åŠ¡')
                    todo_list_str += f"  #{task_id}: {task_desc})\n"
                logger.info(f"[TODOçŠ¶æ€å˜æ›´]\n{todo_list_str}")
        
        # å…¼å®¹æ—§æ ¼å¼ï¼šæ£€æŸ¥ tool_output å­—æ®µ
        elif current_tool_output and current_tool_output.get('tool_output'):
            todo_data = current_tool_output['tool_output']
            if 'todo_list' in todo_data:
                # TodoGenerator æ—§æ ¼å¼è¾“å‡º
                state.todo = todo_data['todo_list']
                logger.info(f"[REFLECTION] TodoGenerator (æ—§æ ¼å¼) åˆ›å»ºäº† {len(state.todo)} ä¸ªä»»åŠ¡")
                # åˆå¹¶æ‰€æœ‰TODOä¿¡æ¯åˆ°ä¸€ä¸ªæ—¥å¿—æ¡ç›®
                todo_list_str = "========== TodoGeneratoråˆ›å»ºTODOæ¸…å• ==========\n"
                for idx, task in enumerate(state.todo, 1):
                    task_id = task.get('id', '?')
                    task_desc = task.get('task', 'æœªçŸ¥ä»»åŠ¡')
                    todo_list_str += f"  #{task_id}: {task_desc})\n"
                logger.info(f"[TODOçŠ¶æ€å˜æ›´]\n{todo_list_str}")
        
        # ä¹Ÿæ£€æŸ¥ç›´æ¥çš„tool_outputæ ¼å¼ (æŸäº›æƒ…å†µä¸‹å¯èƒ½ç›´æ¥åœ¨tool_outputæ ¹çº§åˆ«)
        elif current_tool_output and 'todo_list' in current_tool_output:
            state.todo = current_tool_output['todo_list']
            logger.info(f"[REFLECTION] TodoGenerator ç›´æ¥è¾“å‡ºåˆ›å»ºäº† {len(state.todo)} ä¸ªä»»åŠ¡")
            # åˆå¹¶æ‰€æœ‰TODOä¿¡æ¯åˆ°ä¸€ä¸ªæ—¥å¿—æ¡ç›®
            todo_list_str = "========== TodoGeneratoråˆ›å»ºTODOæ¸…å• ==========\n"
            for idx, task in enumerate(state.todo, 1):
                task_id = task.get('id', '?')
                task_desc = task.get('task', 'æœªçŸ¥ä»»åŠ¡')
                todo_list_str += f"  #{task_id}: {task_desc})\n"
            logger.info(f"[TODOçŠ¶æ€å˜æ›´]\n{todo_list_str}")
    
    # æ·»åŠ  reflection æ•°æ®åˆ° action_history
    # ç”Ÿæˆå”¯ä¸€çš„ action_id
    timestamp = datetime.now()
    action_id = f"action_{timestamp.strftime('%Y%m%d_%H%M%S_%f')}"
    
    if reflection_data:
        reflection_data["action_id"] = action_id  # æ·»åŠ  action_id å…³è”
        # action_history å¿…é¡»æ˜¯åµŒå¥—åˆ—è¡¨ç»“æ„ï¼šæ·»åŠ åˆ°æœ€åä¸€ä¸ªå­åˆ—è¡¨ï¼ˆå½“å‰å¯¹è¯ï¼‰
        if not state.action_history:
            # å¦‚æœä¸ºç©ºï¼Œåˆå§‹åŒ–ä¸ºåµŒå¥—ç»“æ„
            state.action_history = [[{
                "type": "reflection",
                "data": reflection_data
            }]]
        elif not isinstance(state.action_history[-1], list):
            # æ ¼å¼ä¸åˆæ³•
            raise ValueError("action_history å¿…é¡»æ˜¯åµŒå¥—åˆ—è¡¨æ ¼å¼")
        else:
            # æ·»åŠ åˆ°æœ€åä¸€ä¸ªå­åˆ—è¡¨
            state.action_history[-1].append({
                "type": "reflection",
                "data": reflection_data
            })
    
    # æ¸…é™¤æ•°æ®ç›®å½•ç¼“å­˜
    state._data_catalog_cache = None
    
    # åˆå¹¶æ—¥å¿—è¾“å‡º
    logger.info(
        f"[REFLECTION] æ›´æ–°çŠ¶æ€:\n"
        f"  - æ·»åŠ  reflection: {action_id} - {current_plan.tool_name}\n"
        f"  - action_history æ€»æ¡ç›®: {len(state.action_history)}\n"
        f"  - å·²æ¸…é™¤æ•°æ®ç›®å½•ç¼“å­˜"
    )
    
    # å­˜å‚¨å®Œæ•´æ•°æ®ï¼ˆä¿ç•™ä»¥ä¾¿å…¶ä»–åœ°æ–¹å¯èƒ½ä¾èµ–ï¼‰
    state.full_action_data[action_id] = {
        "plan": current_plan.model_dump(),
        "tool_output": current_tool_output,
        "reflection": llm_reflection_result.model_dump()
    }
    
    # æ£€æŸ¥å¹¶æ›´æ–°TODOä»»åŠ¡çŠ¶æ€
    if state.todo and len(state.todo) > 0:
        tool_name = current_plan.tool_name
        tool_status = current_tool_output.get("status", "unknown")
        
        # è®°å½•æ›´æ–°çš„ä»»åŠ¡
        updated_tasks = []
        task_check_logs = []  # æ”¶é›†ä»»åŠ¡æ£€æŸ¥æ—¥å¿—
        
        for todo_item in state.todo:
            # è·³è¿‡å·²å®Œæˆæˆ–å¤±è´¥çš„ä»»åŠ¡
            if todo_item.get('status', 'pending') in ['completed', 'failed']:
                continue
            
            # åªå¤„ç†processingçŠ¶æ€çš„ä»»åŠ¡ï¼ˆæ­£åœ¨æ‰§è¡Œçš„ä»»åŠ¡ï¼‰
            if todo_item.get('status') != 'processing':
                continue
            
            task_id = todo_item.get('id', '?')
            task_desc = todo_item.get('task', '')
            suggested_tools = todo_item.get('suggested_tools', [])
            
            # æ›´å®½æ¾çš„æ¡ä»¶ï¼šæ£€æŸ¥å·¥å…·æ˜¯å¦ç›¸å…³ï¼ˆä¸è¦æ±‚ä¸¥æ ¼åŒ¹é…suggested_toolsï¼‰
            # 1. é¦–å…ˆæ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†å»ºè®®çš„å·¥å…·
            is_suggested_tool = tool_name in suggested_tools
            
            # 2. å¦‚æœä¸åœ¨å»ºè®®å·¥å…·ä¸­ï¼Œæ£€æŸ¥å·¥å…·æ˜¯å¦ä¸ä»»åŠ¡ç›¸å…³
            # ä¾‹å¦‚ï¼šTextGeneratorå¯èƒ½ç”¨äºå¤šç§æ–‡æœ¬ç”Ÿæˆä»»åŠ¡
            tool_keywords = {
                'TextGenerator': ['åˆ†æ', 'æ€»ç»“', 'ç”Ÿæˆ', 'æå–', 'æ•´åˆ', 'è¯„ä¼°'],
                'GoogleSearch': ['æœç´¢', 'æŸ¥æ‰¾', 'æ£€ç´¢', 'æŸ¥è¯¢'],
                'knowledge_base': ['çŸ¥è¯†åº“', 'æŸ¥è¯¢', 'æ£€ç´¢', 'æ–‡æ¡£'],
            }
            
            # æ£€æŸ¥å·¥å…·æ˜¯å¦å¯èƒ½å®Œæˆè¯¥ä»»åŠ¡
            is_related_tool = False
            if tool_name in tool_keywords:
                is_related_tool = any(kw in task_desc for kw in tool_keywords[tool_name])
            
            # å¦‚æœå·¥å…·ç›¸å…³ï¼ˆå»ºè®®çš„æˆ–ç›¸å…³çš„ï¼‰
            if is_suggested_tool or is_related_tool:
                task_check_logs.append(f"  - ä»»åŠ¡{task_id}ä½¿ç”¨äº†{'å»ºè®®' if is_suggested_tool else 'ç›¸å…³'}å·¥å…· {tool_name}")
                
                # æ£€æŸ¥å·¥å…·æ‰§è¡Œæ˜¯å¦æˆåŠŸä¸”ç»“æœå……åˆ†
                if tool_status == "success" and llm_reflection_result.is_sufficient:
                    # æ›´æ™ºèƒ½çš„ç›¸å…³æ€§æ£€æŸ¥ï¼šåŸºäºä»»åŠ¡æè¿°å’Œå·¥å…·è¾“å…¥/è¾“å‡ºçš„è¯­ä¹‰ç›¸å…³æ€§
                    tool_input_str = str(current_plan.tool_input) if current_plan.tool_input else ""
                    tool_output_str = str(current_tool_output.get('data', ''))[:500]  # æ£€æŸ¥è¾“å‡ºçš„å‰500å­—ç¬¦
                    reflection_text = llm_reflection_result.conclusion if hasattr(llm_reflection_result, 'conclusion') else ''
                    
                    # æå–ä»»åŠ¡å…³é”®è¯ï¼ˆè¿‡æ»¤æ‰å¤ªçŸ­çš„è¯ï¼‰
                    task_keywords = [kw for kw in task_desc.lower().split() if len(kw) > 2]
                    
                    # æ£€æŸ¥ä»»åŠ¡å…³é”®è¯æ˜¯å¦å‡ºç°åœ¨å·¥å…·è¾“å…¥ã€è¾“å‡ºæˆ–åæ€ç»“è®ºä¸­
                    combined_text = f"{tool_input_str} {tool_output_str} {reflection_text}".lower()
                    is_relevant = any(keyword in combined_text for keyword in task_keywords) if task_keywords else True
                    
                    if is_relevant:
                        # ã€å…³é”®ä¿®å¤ã€‘æ£€æŸ¥ä»»åŠ¡ä¾èµ–æ˜¯å¦æ»¡è¶³
                        dependencies = todo_item.get('dependencies', [])
                        dependencies_met = True
                        unmet_dependencies = []
                        
                        if dependencies:
                            for dep_id in dependencies:
                                # æŸ¥æ‰¾ä¾èµ–ä»»åŠ¡
                                dep_task = next((t for t in state.todo if t.get('id') == dep_id), None)
                                if not dep_task or dep_task.get('status', 'pending') != 'completed':
                                    dependencies_met = False
                                    unmet_dependencies.append(dep_id)
                            
                            if not dependencies_met:
                                logger.warning(
                                    f"[TODOä¾èµ–æ£€æŸ¥] âš ï¸ ä»»åŠ¡{task_id}çš„ä¾èµ–æœªæ»¡è¶³\n"
                                    f"  éœ€è¦å…ˆå®Œæˆ: {unmet_dependencies}\n"
                                    f"  è™½ç„¶å·¥å…·æ‰§è¡ŒæˆåŠŸï¼Œä½†ä¸èƒ½æ ‡è®°ä¸ºå®Œæˆ"
                                )
                                continue  # è·³è¿‡æ­¤ä»»åŠ¡ï¼Œä¸æ ‡è®°ä¸ºå®Œæˆ
                            else:
                                logger.info(f"[TODOä¾èµ–æ£€æŸ¥] âœ… ä»»åŠ¡{task_id}çš„æ‰€æœ‰ä¾èµ–å·²æ»¡è¶³: {dependencies}")
                        
                        # ä¾èµ–æ»¡è¶³ï¼Œå¯ä»¥æ ‡è®°ä¸ºå®Œæˆ
                        old_status = todo_item.get('status', 'processing')
                        todo_item['status'] = 'completed'  # æ›´æ–°statuså­—æ®µ
                        todo_item['completed_at'] = datetime.now().isoformat()  # ã€æ–°å¢ã€‘è®°å½•å®Œæˆæ—¶é—´
                        
                        # ã€æ–°å¢ã€‘è®¡ç®—æ‰§è¡Œæ—¶é—´
                        if 'started_at' in todo_item:
                            try:
                                start_time = datetime.fromisoformat(todo_item['started_at'])
                                execution_time = (datetime.now() - start_time).total_seconds()
                                todo_item['execution_time'] = execution_time
                                logger.info(f"[TODOæ‰§è¡Œæ—¶é—´] ä»»åŠ¡{task_id}æ‰§è¡Œè€—æ—¶: {execution_time:.1f}ç§’")
                            except:
                                pass
                        
                        updated_tasks.append(task_id)
                        # é‡ç½®é‡è¯•è®¡æ•°ï¼ˆæˆåŠŸå®Œæˆï¼‰
                        if 'retry' in todo_item:
                            logger.info(f"[TODOçŠ¶æ€å˜æ›´] ä»»åŠ¡{task_id}åœ¨ç¬¬{todo_item['retry']+1}æ¬¡å°è¯•åæˆåŠŸå®Œæˆ")
                        
                        # è¯¦ç»†è®°å½•ä»»åŠ¡å®Œæˆï¼ˆåˆå¹¶æˆä¸€æ¡æ—¥å¿—ï¼‰
                        execution_info = ""
                        if 'execution_time' in todo_item:
                            execution_info = f"\n  æ‰§è¡Œè€—æ—¶: {todo_item['execution_time']:.1f}ç§’"
                        
                        logger.info(
                            f"[TODOçŠ¶æ€å˜æ›´] ========== ä»»åŠ¡å®Œæˆ ==========\n"
                            f"  ä»»åŠ¡ID: {task_id}\n"
                            f"  ä»»åŠ¡æè¿°: {task_desc[:100]}\n"
                            f"  çŠ¶æ€å˜æ›´: {old_status} â†’ completed\n"
                            f"  æ‰§è¡Œå·¥å…·: {tool_name}\n"
                            f"  å®Œæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}{execution_info}\n"
                            f"  å…³è”Action: {action_summary.action_id}"
                        )
                        
                        # è®°å½•å®Œæˆè¯¦æƒ…
                        reflection_summary = ''
                        if hasattr(llm_reflection_result, 'conclusion'):
                            reflection_summary = llm_reflection_result.conclusion
                        elif hasattr(llm_reflection_result, 'evaluation'):
                            reflection_summary = llm_reflection_result.evaluation
                        
                        todo_item['completion_details'] = {
                            'completed_at': datetime.now().isoformat(),
                            'completed_by_tool': tool_name,
                            'action_id': action_summary.action_id,
                            'result_summary': reflection_summary[:200] if reflection_summary else "",
                            'tool_status': tool_status
                        }
                        
                        # é€šå¸¸ä¸€æ¬¡æ‰§è¡Œåªå®Œæˆä¸€ä¸ªä¸»è¦ä»»åŠ¡ï¼Œä½†ç»§ç»­æ£€æŸ¥ä»¥é˜²æœ‰å…³è”ä»»åŠ¡
                    else:
                        task_check_logs.append(f"  - ä»»åŠ¡{task_id}ä½¿ç”¨äº†{'å»ºè®®' if is_suggested_tool else 'ç›¸å…³'}å·¥å…·ï¼Œä½†æ‰§è¡Œå†…å®¹ä¸ä»»åŠ¡æè¿°ç›¸å…³æ€§ä¸é«˜")
                        task_check_logs.append(f"    ä»»åŠ¡å…³é”®è¯: {task_keywords}")
                        task_check_logs.append(f"    å·¥å…·è¾“å…¥å‰100å­—ç¬¦: {tool_input_str[:100]}")
                elif tool_status == "success" and not llm_reflection_result.is_sufficient:
                    task_check_logs.append(f"  - ä»»åŠ¡{task_id}æ‰§è¡ŒæˆåŠŸä½†ç»“æœä¸å……åˆ†ï¼Œæš‚ä¸æ ‡è®°ä¸ºå®Œæˆ")
                elif tool_status != "success":
                    # ã€å¢å¼ºã€‘ä»»åŠ¡å¤±è´¥æ—¶çš„é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
                    task_check_logs.append(f"  - âš ï¸ ä»»åŠ¡{task_id}æ‰§è¡Œå¤±è´¥ï¼ˆstatus={tool_status}ï¼‰")
                    
                    # æ›´æ–°é‡è¯•è®¡æ•°
                    current_retry = todo_item.get('retry', 0)
                    max_retry = todo_item.get('max_retry', 3)  # é»˜è®¤3æ¬¡é‡è¯•
                    todo_item['retry'] = current_retry + 1
                    
                    # è®°å½•é”™è¯¯å†å²
                    if 'error_history' not in todo_item:
                        todo_item['error_history'] = []
                    
                    todo_item['error_history'].append({
                        'timestamp': datetime.now().isoformat(),
                        'tool': tool_name,
                        'status': tool_status,
                        'error': current_tool_output.get('error', 'æœªçŸ¥é”™è¯¯'),
                        'retry_count': todo_item['retry'],
                        'execution_time': current_tool_output.get('execution_time', 0)
                    })
                    
                    # ã€æ–°å¢ã€‘è®¡ç®—æŒ‡æ•°é€€é¿å»¶è¿Ÿï¼ˆ1ç§’ã€2ç§’ã€4ç§’ã€8ç§’ï¼‰
                    backoff_delay = min(2 ** (current_retry - 1), 8)  # æœ€å¤§å»¶è¿Ÿ8ç§’
                    
                    # ã€æ–°å¢ã€‘æ£€æŸ¥æ˜¯å¦è¶…æ—¶ï¼ˆå¦‚æœæœ‰å¼€å§‹æ—¶é—´ï¼‰
                    is_timeout = False
                    if 'started_at' in todo_item:
                        elapsed = (datetime.now() - datetime.fromisoformat(todo_item['started_at'])).total_seconds()
                        task_timeout = todo_item.get('timeout', 300)  # é»˜è®¤5åˆ†é’Ÿè¶…æ—¶
                        if elapsed > task_timeout:
                            is_timeout = True
                            task_check_logs.append(f"  - â° ä»»åŠ¡{task_id}å·²è¶…æ—¶ï¼ˆ{elapsed:.1f}ç§’ > {task_timeout}ç§’ï¼‰")
                    
                    # æ ¹æ®é‡è¯•æ¬¡æ•°å’Œè¶…æ—¶æƒ…å†µå†³å®šå¤„ç†ç­–ç•¥
                    if not is_timeout and todo_item['retry'] <= max_retry:
                        logger.info(f"[TODOé‡è¯•æœºåˆ¶] ä»»åŠ¡{task_id}å°†åœ¨{backoff_delay}ç§’åé‡è¯•ï¼ˆå·²å°è¯•{todo_item['retry']}æ¬¡/æœ€å¤§{max_retry}æ¬¡ï¼‰")
                        todo_item['status'] = 'pending'  # å›åˆ°pendingçŠ¶æ€
                        todo_item['retry_after'] = (datetime.now() + timedelta(seconds=backoff_delay)).isoformat()
                        
                        # ã€æ–°å¢ã€‘æ ¹æ®é”™è¯¯ç±»å‹è°ƒæ•´é‡è¯•ç­–ç•¥
                        error_msg = str(current_tool_output.get('error', '')).lower()
                        if 'rate limit' in error_msg or 'too many requests' in error_msg:
                            # APIé™é€Ÿé”™è¯¯ï¼Œå¢åŠ å»¶è¿Ÿ
                            todo_item['retry_after'] = (datetime.now() + timedelta(seconds=backoff_delay * 2)).isoformat()
                            logger.info(f"[TODOé‡è¯•æœºåˆ¶] æ£€æµ‹åˆ°APIé™é€Ÿï¼Œå»¶é•¿é‡è¯•é—´éš”è‡³{backoff_delay * 2}ç§’")
                        elif 'network' in error_msg or 'connection' in error_msg:
                            # ç½‘ç»œé”™è¯¯ï¼Œå¿«é€Ÿé‡è¯•
                            todo_item['retry_after'] = (datetime.now() + timedelta(seconds=1)).isoformat()
                            logger.info(f"[TODOé‡è¯•æœºåˆ¶] æ£€æµ‹åˆ°ç½‘ç»œé”™è¯¯ï¼Œ1ç§’åå¿«é€Ÿé‡è¯•")
                    else:
                        # è¶…è¿‡é‡è¯•æ¬¡æ•°æˆ–è¶…æ—¶ï¼Œæ ‡è®°ä¸ºå¤±è´¥
                        failure_reason = "è¶…æ—¶" if is_timeout else f"é‡è¯•{todo_item['retry']}æ¬¡åä»å¤±è´¥"
                        logger.error(f"[TODOé‡è¯•æœºåˆ¶] ä»»åŠ¡{task_id}æœ€ç»ˆå¤±è´¥ï¼š{failure_reason}")
                        todo_item['status'] = 'failed'
                        todo_item['failed_at'] = datetime.now().isoformat()
                        todo_item['failure_reason'] = failure_reason
            else:
                # ä¸æ˜¯å»ºè®®çš„å·¥å…·ï¼Œä½†ä»ç„¶æ£€æŸ¥æ˜¯å¦å¯èƒ½å®Œæˆäº†ä»»åŠ¡
                # ä¾‹å¦‚ï¼šæŸäº›é€šç”¨å·¥å…·å¯èƒ½å®Œæˆå¤šç§ä»»åŠ¡
                logger.debug(f"[REFLECTION] ä»»åŠ¡{task_id}æœªä½¿ç”¨å»ºè®®å·¥å…·ï¼ˆå»ºè®®ï¼š{suggested_tools}ï¼Œå®é™…ï¼š{tool_name}ï¼‰")
        
        # å¾ªç¯ç»“æŸåï¼Œæ£€æŸ¥æ˜¯å¦æœ‰ä»»åŠ¡è¢«æ›´æ–°
        if updated_tasks:
            # ã€å¢å¼ºã€‘ç»Ÿè®¡å½“å‰è¿›åº¦ï¼ŒåŒ…æ‹¬å„ç§çŠ¶æ€
            completed_count = sum(1 for t in state.todo if t.get('status') == 'completed')
            failed_count = sum(1 for t in state.todo if t.get('status') == 'failed')
            pending_count = sum(1 for t in state.todo if t.get('status', 'pending') == 'pending')
            total_count = len(state.todo)
            progress_percentage = (completed_count / total_count * 100) if total_count > 0 else 0
            
            logger.info(f"[TODOçŠ¶æ€å˜æ›´] ========== è¿›åº¦æ›´æ–°æ±‡æ€» ==========")
            logger.info(f"[TODOçŠ¶æ€å˜æ›´] æœ¬æ¬¡æ ‡è®°å®Œæˆ: {len(updated_tasks)} ä¸ªä»»åŠ¡")
            logger.info(f"[TODOçŠ¶æ€å˜æ›´] å®Œæˆçš„ä»»åŠ¡ID: {updated_tasks}")
            logger.info(f"[TODOçŠ¶æ€å˜æ›´] æ€»ä½“è¿›åº¦: å®Œæˆ{completed_count}/{total_count} ({progress_percentage:.0f}%)")
            logger.info(f"[TODOçŠ¶æ€å˜æ›´] çŠ¶æ€åˆ†å¸ƒ: âœ…å®Œæˆ={completed_count} â³å¾…æ‰§è¡Œ={pending_count} âŒå¤±è´¥={failed_count}")
            
            # ã€æ–°å¢ã€‘å…³é”®è·¯å¾„å¯è§†åŒ–æ—¥å¿—
            _visualize_critical_path(state.todo)
            
            # åˆ—å‡ºå‰©ä½™æœªå®Œæˆçš„ä»»åŠ¡
            remaining_tasks = [t.get('id') for t in state.todo if t.get('status', 'pending') != 'completed']
            if remaining_tasks:
                logger.info(f"[TODOçŠ¶æ€å˜æ›´] å‰©ä½™ä»»åŠ¡ID: {remaining_tasks}")
            else:
                logger.info(f"[TODOçŠ¶æ€å˜æ›´] ğŸ‰ æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆï¼")
        else:
            task_check_logs.append("  - æ²¡æœ‰ä»»åŠ¡è¢«æ ‡è®°ä¸ºå®Œæˆ")
        
        # è¾“å‡ºåˆå¹¶çš„ä»»åŠ¡æ£€æŸ¥æ—¥å¿—
        if task_check_logs:
            logger.info(
                f"[REFLECTION] TODOä»»åŠ¡æ£€æŸ¥ (å…±{len(state.todo)}ä¸ªä»»åŠ¡):\n" + 
                "\n".join(task_check_logs)
            )
    
    
    # æ³¨ï¼šå…³äº context çš„è®¾è®¡æ€è€ƒ
    # context åº”è¯¥ç”¨äºå­˜å‚¨è·¨æ­¥éª¤çš„å…³é”®æ´å¯Ÿï¼Œè€Œä¸æ˜¯æ‰§è¡Œå†å²
    # æ‰§è¡Œå†å²å·²ç»ç”± full_action_data å¾ˆå¥½åœ°å¤„ç†äº†
    # 
    # æœªæ¥å¯ä»¥è€ƒè™‘ï¼š
    # 1. è®© planner ä¸»åŠ¨å†³å®šä»€ä¹ˆä¿¡æ¯éœ€è¦åŠ å…¥ context
    # 2. æˆ–è€…ç”± reflection èŠ‚ç‚¹åˆ¤æ–­æŸäº›å‘ç°ç‰¹åˆ«é‡è¦éœ€è¦ä¿ç•™
    # 3. context åº”è¯¥æ˜¯å°‘é‡çš„ã€é«˜ä»·å€¼çš„ä¿¡æ¯
    #
    # æš‚æ—¶ä¿ç•™ç©ºå®ç°ï¼Œé¿å…ç ´åç°æœ‰é€»è¾‘
    # TODO: é‡æ–°è®¾è®¡ context çš„ä½¿ç”¨ç­–ç•¥
    
    # æ³¨æ„ï¼šcurrent_plan å’Œ current_tool_output ç°åœ¨ä½œä¸ºå‚æ•°ä¼ å…¥ï¼Œä¸å†å­˜å‚¨åœ¨stateä¸­
    
    # è®°å½•åæ€å®Œæˆçš„æ—¥å¿—ä¿¡æ¯
    # è¿”å›æ›´æ–°åçš„è¡ŒåŠ¨å†å²ï¼Œå°½ç®¡ RuntimeState å®ä¾‹æœ¬èº«å·²è¢«ä¿®æ”¹ï¼Œä½†è¿”å›æ­¤å­—å…¸å¯ä»¥æ–¹ä¾¿åç»­å¤„ç†
    return {"action_history": state.action_history}


def _visualize_critical_path(todo_list):
    """
    ã€æ–°å¢ã€‘å¯è§†åŒ–å…³é”®è·¯å¾„ï¼Œæ˜¾ç¤ºä»»åŠ¡ä¾èµ–å…³ç³»å’Œæ‰§è¡Œé¡ºåº
    """
    if not todo_list:
        return
    
    # æ„å»ºä»»åŠ¡ä¾èµ–å›¾
    task_map = {t.get('id'): t for t in todo_list}
    
    # æ‰¾å‡ºæ²¡æœ‰ä¾èµ–çš„æ ¹ä»»åŠ¡
    root_tasks = [t for t in todo_list if not t.get('dependencies', [])]
    
    # æ‰¾å‡ºæ¯ä¸ªä»»åŠ¡çš„åç»­ä»»åŠ¡
    dependents_map = {}
    for task in todo_list:
        task_id = task.get('id')
        dependents_map[task_id] = []
        for dep in task.get('dependencies', []):
            if dep not in dependents_map:
                dependents_map[dep] = []
            dependents_map[dep].append(task_id)
    
    # è®¡ç®—å…³é”®è·¯å¾„é•¿åº¦
    def calculate_path_length(task_id, visited=None):
        if visited is None:
            visited = set()
        if task_id in visited:
            return 0
        visited.add(task_id)
        
        if task_id not in dependents_map or not dependents_map[task_id]:
            return 1
        
        max_length = 0
        for dep_id in dependents_map[task_id]:
            length = calculate_path_length(dep_id, visited.copy())
            max_length = max(max_length, length)
        return 1 + max_length
    
    # æ‰¾å‡ºå…³é”®è·¯å¾„ï¼ˆæœ€é•¿è·¯å¾„ï¼‰
    critical_paths = []
    for root in root_tasks:
        path_length = calculate_path_length(root.get('id'))
        critical_paths.append((root.get('id'), path_length))
    
    # æŒ‰è·¯å¾„é•¿åº¦æ’åº
    critical_paths.sort(key=lambda x: x[1], reverse=True)
    
    if critical_paths:
        # æ„å»ºå…³é”®è·¯å¾„çš„å¯è§†åŒ–å­—ç¬¦ä¸²
        path_viz = "[TODOå…³é”®è·¯å¾„] ========== å…³é”®è·¯å¾„åˆ†æ ==========\n"
        
        # æ˜¾ç¤ºå‰3æ¡å…³é”®è·¯å¾„
        for i, (task_id, length) in enumerate(critical_paths[:3], 1):
            task = task_map.get(task_id)
            if task:
                status_icon = {
                    'completed': 'âœ…',
                    'processing': 'âš¡',
                    'failed': 'âŒ',
                    'pending': 'â³'
                }.get(task.get('status', 'pending'), 'â³')
                
                path_viz += f"  è·¯å¾„{i}: {status_icon} ä»»åŠ¡{task_id}(é•¿åº¦:{length})"
                
                # æ˜¾ç¤ºè·¯å¾„ä¸Šçš„ä»»åŠ¡é“¾
                current_id = task_id
                path_chain = [f"{task_id}"]
                while current_id in dependents_map and dependents_map[current_id]:
                    # é€‰æ‹©æœ€é•¿çš„åç»­è·¯å¾„
                    next_tasks = [(t, calculate_path_length(t)) for t in dependents_map[current_id]]
                    if next_tasks:
                        next_tasks.sort(key=lambda x: x[1], reverse=True)
                        current_id = next_tasks[0][0]
                        path_chain.append(str(current_id))
                    else:
                        break
                    
                    if len(path_chain) > 5:  # é™åˆ¶æ˜¾ç¤ºé•¿åº¦
                        path_chain.append("...")
                        break
                
                if len(path_chain) > 1:
                    path_viz += " -> " + " -> ".join(path_chain[1:])
                path_viz += "\n"
        
        # ç»Ÿè®¡ä¿¡æ¯
        pending_critical = sum(1 for tid, _ in critical_paths if task_map.get(tid, {}).get('status', 'pending') == 'pending')
        completed_critical = sum(1 for tid, _ in critical_paths if task_map.get(tid, {}).get('status') == 'completed')
        
        path_viz += f"  å…³é”®è·¯å¾„ç»Ÿè®¡: æ€»è®¡{len(critical_paths)}æ¡ | å¾…å¤„ç†{pending_critical}æ¡ | å·²å®Œæˆ{completed_critical}æ¡"
        
        logger.info(path_viz)
# -*- coding: utf-8 -*-
"""
planner.py

è§„åˆ’å™¨èŠ‚ç‚¹æ¨¡å—ã€‚è´Ÿè´£æ ¹æ®å½“å‰è¿è¡Œæ—¶çŠ¶æ€ã€å¯ç”¨å·¥å…·å’Œå›¾ç»“æ„ä¿¡æ¯ï¼Œ
åˆ©ç”¨LLMè§„åˆ’ä¸‹ä¸€æ­¥æœ€å…³é”®çš„è¡ŒåŠ¨ã€‚
"""

import re, json
import logging
from ..utils.logger_config import logger, log_llm_request, log_llm_response
from typing import Dict, Any, Optional

from tools.core.registry import ToolRegistry
from llm.core_service import CoreLLMService
from llm.config_manager import ModelConfigManager
from ..core.schemas import RuntimeState, PlannerOutput
from .components import safe_json_dumps as _safe_json_dumps
from .components import replace_data_markers


def planner_node(state: RuntimeState, nodes_map: Optional[Dict[str, Any]] = None, edges_map: Optional[Dict[str, Any]] = None, 
                 user=None, session_id: Optional[str] = None) -> Dict[str, Any]:
    """
    è§„åˆ’å™¨èŠ‚ç‚¹å‡½æ•°ã€‚
    æ ¹æ®å½“å‰çš„è¿è¡Œæ—¶çŠ¶æ€ã€å¯ç”¨å·¥å…·å’Œå›¾ç»“æ„ä¿¡æ¯ï¼Œåˆ©ç”¨LLMè§„åˆ’ä¸‹ä¸€æ­¥æœ€å…³é”®çš„è¡ŒåŠ¨ã€‚
    å®ƒä¼šç”Ÿæˆä¸€ä¸ªåŒ…å«æ€è€ƒè¿‡ç¨‹ã€è¡ŒåŠ¨ç±»å‹ï¼ˆè°ƒç”¨å·¥å…·æˆ–å®Œæˆä»»åŠ¡ï¼‰ã€å·¥å…·åç§°å’Œå·¥å…·è¾“å…¥çš„è§„åˆ’ã€‚

    å‚æ•°:
    state (RuntimeState): å½“å‰çš„è¿è¡Œæ—¶çŠ¶æ€ï¼ŒåŒ…å«ä»»åŠ¡ç›®æ ‡ã€è¡ŒåŠ¨å†å²ç­‰ã€‚
    nodes_map (Optional[Dict[str, Any]]): åŒ…å«å›¾ä¸­æ‰€æœ‰èŠ‚ç‚¹çš„å­—å…¸ï¼Œç”¨äºè·å–èŠ‚ç‚¹é…ç½®ã€‚
    edges_map (Optional[Dict[str, Any]]): åŒ…å«å›¾ä¸­æ‰€æœ‰è¾¹çš„å­—å…¸ï¼Œç”¨äºæ ¼å¼åŒ–å›¾ç»“æ„ä¿¡æ¯ã€‚
    user: ç”¨æˆ·å¯¹è±¡ï¼ˆç”¨äºæ—¥å¿—è®°å½•ï¼‰
    session_id (Optional[str]): ä¼šè¯IDï¼ˆç”¨äºæ—¥å¿—è®°å½•ï¼‰

    è¿”å›:
    Dict[str, Any]: åŒ…å«LLMç”Ÿæˆçš„å½“å‰è§„åˆ’çš„å­—å…¸ï¼Œé”®ä¸º"current_plan"ã€‚
    """
    # æ£€æŸ¥æ˜¯å¦å¯ç”¨é“¾å¼æ¶æ„
    import os
    enable_chain = os.getenv('ENABLE_PLANNER_CHAIN', 'true').lower() == 'true'

    
    # å¦‚æœä¸å¯ç”¨é“¾å¼æ¶æ„æˆ–é“¾å¼æ¶æ„å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹å®ç°
    if not enable_chain:
        logger.info(f"[PLANNER] ä½¿ç”¨åŸå§‹å®ç°å¤„ç†ä»»åŠ¡: {state.task_goal[:100]}")
        return _original_planner_implementation(state, nodes_map, edges_map, user, session_id)


def _original_planner_implementation(state: RuntimeState, nodes_map: Optional[Dict[str, Any]] = None, 
                                    edges_map: Optional[Dict[str, Any]] = None, 
                                    user=None, session_id: Optional[str] = None) -> Dict[str, Any]:
    """
    åŸå§‹çš„planner_nodeå®ç°
    """
    # è®°å½•è§„åˆ’å™¨å¼€å§‹è§„åˆ’
    logger.info(f"[PLANNER-ORIGINAL] Starting planning for task: {state.task_goal[:100]}")
    try:
        # å®ä¾‹åŒ–æ ¸å¿ƒLLMæœåŠ¡å’Œé…ç½®ç®¡ç†å™¨
        core_service = CoreLLMService()
        config_manager = ModelConfigManager()
        
        # ä½¿ç”¨ç»Ÿä¸€çš„æ¨¡å‹é…ç½®æœåŠ¡è·å–æ¨¡å‹åç§°
        from agentic.core.model_config_service import NodeModelConfigService
        model_name = NodeModelConfigService.get_model_for_node('planner', nodes_map)
        
        # è·å–æ¨¡å‹é…ç½®ï¼ˆå·²åŒ…å«vendor_nameï¼‰
        model_config = config_manager.get_model_config(model_name)
        
        # è·å–ä¸€ä¸ªç»“æ„åŒ–è¾“å‡ºçš„LLMå®ä¾‹ï¼Œå…¶è¾“å‡ºå°†ä¸¥æ ¼ç¬¦åˆPlannerOutput Pydanticæ¨¡å‹
        LLM = core_service.get_structured_llm(
            PlannerOutput, 
            model_config,
            user=user,
            session_id=session_id,
            model_name=model_name,
            source_app='agentic',
            source_function='nodes.planner.planner_node'
        )
        
        # åœ¨å‡½æ•°å†…éƒ¨ç›´æ¥æ„å»ºæç¤ºè¯ï¼Œä¸å†è°ƒç”¨å¤–éƒ¨å‡½æ•°
        system_prompt, user_prompt = _build_prompt_internal(state, nodes_map)
    except Exception as e:
        logger.error(f"[PLANNER] æ„å»º prompt å¤±è´¥: {str(e)}")
        raise
    
    # æ‰“å°å®Œæ•´çš„ prompt ä¿¡æ¯ç”¨äºè°ƒè¯•ï¼ˆå•ä¸ª logger è°ƒç”¨ï¼‰
    prompt_debug_info = f"""
{"=" * 10}
ğŸ“Š PLANNER NODE - å®Œæ•´è¯·æ±‚ä¿¡æ¯
System Prompt é•¿åº¦: {len(system_prompt)} å­—ç¬¦
User Prompt é•¿åº¦: {len(user_prompt)} å­—ç¬¦

{"=" * 10}
ã€System Promptã€‘
{system_prompt}

{"=" * 10}
ã€User Promptã€‘
{user_prompt}
{"=" * 10}
"""
    # è®°å½•LLMè¯·æ±‚
    log_llm_request("planner", system_prompt, user_prompt, model_name)
    
    try:
        # è°ƒç”¨ LLM è¿›è¡Œè§„åˆ’ï¼Œä¼ å…¥ç³»ç»Ÿæç¤ºè¯å’Œç”¨æˆ·æç¤ºè¯
        llm_result = LLM.invoke(user_prompt, system_prompt=system_prompt)
        # è®°å½•LLMå“åº”
        log_llm_response("planner", llm_result)
    except Exception as e:
        if "ç»“æ„åŒ–è¾“å‡ºè§£æå¤±è´¥" in str(e):
            logger.warning("[PLANNER] ç»“æ„åŒ–è¾“å‡ºè§£æå¤±è´¥ï¼Œé‡è¯•ä¸€æ¬¡")
            llm_result = LLM.invoke(user_prompt, system_prompt=system_prompt) # é‡è¯•ä¸€æ¬¡
        else:
            raise e
    
    # LLMç»“æœå·²ç»åœ¨ä¸Šé¢è®°å½•
        
    # å¤„ç† FINISH æ—¶ï¼Œä¸å†ç”Ÿæˆ final_answer
    if llm_result.action == "FINISH":
        
        # æ¸…ç©ºä»»ä½•å¯èƒ½ç”± LLM å¡«å†™çš„ final_answer
        if llm_result.final_answer:
            logger.warning(f"[PLANNER] è­¦å‘Šï¼šPlanner æä¾›äº† final_answerï¼Œä½†ç³»ç»Ÿå°†å¿½ç•¥å®ƒ")
            llm_result.final_answer = None
            llm_result.title = None
    
    # å¦‚æœæ˜¯è°ƒç”¨å·¥å…·ï¼Œå¤„ç†å·¥å…·è¾“å…¥ä¸­çš„æ•°æ®å¼•ç”¨
    elif llm_result.action == "CALL_TOOL" and llm_result.tool_name:
        tool_input = llm_result.tool_input or {}
        
        # ã€è‡ªåŠ¨è¡¥å……ã€‘å¦‚æœæ˜¯TodoGeneratorå·¥å…·ï¼Œè‡ªåŠ¨è¡¥å……ç¼ºå¤±çš„å‚æ•°
        if llm_result.tool_name == "TodoGenerator":
            # è¡¥å……available_toolså‚æ•°
            if "available_tools" not in tool_input:
                logger.info("[PLANNER] æ£€æµ‹åˆ°TodoGeneratorè°ƒç”¨ï¼Œè‡ªåŠ¨è¡¥å……available_toolså‚æ•°")
                # è·å–å·¥å…·æ³¨å†Œè¡¨
                registry = ToolRegistry()
                # ä»…è·å– libs ç±»åˆ«çš„å·¥å…·ï¼Œå¹¶æ’é™¤ TodoGenerator è‡ªèº«
                tools_list = registry.list_tools_with_details(category='libs')
                
                # æ„é€ å¯ç”¨å·¥å…·åˆ—è¡¨ï¼ˆä»…åŒ…å«libsç›®å½•ä¸‹çš„æ‰§è¡Œç±»å·¥å…·ï¼Œæ’é™¤TodoGeneratorï¼‰
                available_tools = []
                for tool_info in tools_list:
                    tool_name = tool_info["name"]
                    # æ’é™¤ TodoGenerator è‡ªèº«
                    if tool_name != 'TodoGenerator':
                        available_tools.append({
                            "name": tool_name,
                            "description": tool_info.get("description", "")
                        })
                
                tool_input["available_tools"] = available_tools
                logger.info(f"[PLANNER] å·²è‡ªåŠ¨æ·»åŠ  {len(available_tools)} ä¸ªå¯ç”¨å·¥å…·åˆ°TodoGeneratorå‚æ•°ï¼ˆä»…libsç±»å·¥å…·ï¼‰")
        
        # æ›¿æ¢æ‰€æœ‰æ•°æ®æ ‡è®°ï¼ˆè°ƒç”¨ components ä¸­çš„å‡½æ•°ï¼‰
        # æ›¿æ¢å‰çš„tool_input
        tool_input = replace_data_markers(tool_input, state)  # ä¼ å…¥ state å‚æ•°
        # æ›¿æ¢åçš„tool_input
        
        # æ›´æ–°å·¥å…·è¾“å…¥
        llm_result.tool_input = tool_input
    
    # å°† plan æ·»åŠ åˆ°è¡ŒåŠ¨å†å²ä¸­
    # æå–å¿…è¦å­—æ®µå¹¶å°†thoughtæ˜ å°„ä¸ºoutputï¼ˆç»Ÿä¸€å­—æ®µåï¼‰
    plan_dict = llm_result.model_dump()
    plan_data = {
        "output": plan_dict.get("thought", ""),  # ç»Ÿä¸€ä½¿ç”¨outputå­—æ®µ
        "action": plan_dict.get("action", ""),
        "tool_name": plan_dict.get("tool_name"),
        "tool_input": plan_dict.get("tool_input")
    }
    
    # action_history å¿…é¡»æ˜¯åµŒå¥—åˆ—è¡¨ç»“æ„ï¼šæ·»åŠ åˆ°æœ€åä¸€ä¸ªå­åˆ—è¡¨ï¼ˆå½“å‰å¯¹è¯ï¼‰
    if not state.action_history:
        # å¦‚æœä¸ºç©ºï¼Œåˆå§‹åŒ–ä¸ºåµŒå¥—ç»“æ„
        state.action_history = [[{
            "type": "plan",
            "data": plan_data
        }]]
    elif not isinstance(state.action_history[-1], list):
        # æ ¼å¼ä¸åˆæ³•
        raise ValueError("action_history å¿…é¡»æ˜¯åµŒå¥—åˆ—è¡¨æ ¼å¼")
    else:
        # æ·»åŠ åˆ°æœ€åä¸€ä¸ªå­åˆ—è¡¨
        state.action_history[-1].append({
            "type": "plan",
            "data": plan_data
        })

    # è®°å½•LLMå†³ç­–å®Œæˆçš„æ—¥å¿—ä¿¡æ¯
    if llm_result.action == "FINISH":
        # ä¸å†åœ¨è¿™é‡Œæ·»åŠ  final_answer æ¡ç›®ï¼Œç”± executor åœ¨è°ƒç”¨ finalizer_node åæ·»åŠ 
        logger.info(f"[PLANNER FINISH] Action: {llm_result.action}, Tool: {llm_result.tool_name}")
        
        # è¾“å‡º output_guidance ä¿¡æ¯
        if hasattr(llm_result, 'output_guidance') and llm_result.output_guidance:
            guidance_dict = llm_result.output_guidance.model_dump() if hasattr(llm_result.output_guidance, 'model_dump') else llm_result.output_guidance
            guidance_json = json.dumps(guidance_dict, ensure_ascii=False, indent=2)
            logger.info(f"[PLANNER] output_guidance: {guidance_json}")
        else:
            logger.warning("[PLANNER] æ—  output_guidance")
    else:
        # è®°å½•è§„åˆ’å™¨ç»“æœ
        logger.info(f"""
[PLANNER] å†³å®šä½¿ç”¨å·¥å…·: {llm_result.tool_name}
å·¥å…·è¾“å…¥:
{_safe_json_dumps(llm_result.tool_input)}
æœŸæœ›è¾“å‡ºç»“æ„:
{_safe_json_dumps(getattr(llm_result, 'expected_outcome', None))}
""")
    
    return {"current_plan": llm_result} # è¿”å›åŒ…å«å½“å‰è§„åˆ’çš„å­—å…¸


# ========== å¯¼å‡ºçš„å·¥å…·å‡½æ•° - ä¾› prompt_builder.py è°ƒç”¨ ==========
# get_tool_descriptions_for_prompt å‡½æ•°å·²ç§»è‡³ components/get_tool_descriptions_for_prompt.py
from .components.get_tool_descriptions_for_prompt import get_tool_descriptions_for_prompt


# build_todo_section_for_prompt å‡½æ•°å·²ç§»è‡³ components/build_todo_section_for_prompt.py
from .components.build_todo_section_for_prompt import build_todo_section_for_prompt

# # build_task_guidance_for_prompt å‡½æ•°å·²ç§»è‡³ components/build_task_guidance_for_prompt.py
# from .components.build_task_guidance_for_prompt import build_task_guidance_for_prompt

# ä½¿ç”¨æ–°çš„åŸºäº action_history çš„æç¤ºè¯æ„å»ºå‡½æ•°
from .components.build_action_history_prompt import build_action_history_prompt

# format_chat_history_for_prompt å‡½æ•°å·²ç§»è‡³ components/format_chat_history_for_prompt.py
from .components.format_chat_history_for_prompt import format_chat_history_for_prompt

# get_data_catalog_summary_for_prompt å‡½æ•°å·²ç§»è‡³ components/get_data_catalog_summary_for_prompt.py
from .components.get_data_catalog_summary_for_prompt import get_data_catalog_summary_for_prompt

# ========== åŸå§‹çš„å†…éƒ¨å®ç°å‡½æ•° ==========

def _build_prompt_internal(state: RuntimeState, nodes_map: Optional[Dict[str, Any]] = None) -> tuple[str, str]:
    """
    åœ¨å‡½æ•°å†…éƒ¨æ„å»ºplanneræç¤ºè¯
    
    å‚æ•°:
    state (RuntimeState): å½“å‰è¿è¡Œæ—¶çŠ¶æ€
    nodes_map (Optional[Dict[str, Any]]): èŠ‚ç‚¹é…ç½®æ˜ å°„
    
    è¿”å›:
    tuple[str, str]: (ç³»ç»Ÿæç¤ºè¯, ç”¨æˆ·æç¤ºè¯)
    """
    # è°ƒç”¨æ¨¡å—çº§åˆ«çš„å¯¼å‡ºå‡½æ•°ï¼Œä¿æŒä»£ç ç»“æ„ä¸€è‡´
    tool_descriptions = get_tool_descriptions_for_prompt()
    # ä½¿ç”¨æ–°çš„åŸºäº action_history çš„æç¤ºè¯æ„å»ºå‡½æ•°
    # å¤„ç†åµŒå¥—åˆ—è¡¨ç»“æ„ï¼šåªä½¿ç”¨å½“å‰å¯¹è¯çš„å†å²
    current_action_history = state.action_history
    if current_action_history and isinstance(current_action_history[-1], list):
        # å¦‚æœæ˜¯åµŒå¥—åˆ—è¡¨ï¼Œä½¿ç”¨æœ€åä¸€ä¸ªå­åˆ—è¡¨ï¼ˆå½“å‰å¯¹è¯ï¼‰
        current_action_history = current_action_history[-1]
    
    action_history_prompt = build_action_history_prompt(
        current_action_history,
        format_type="detailed"  # ä½¿ç”¨è¯¦ç»†æ ¼å¼æ›¿ä»£åŸæœ‰çš„ä¸¤ä¸ªå†å²å‡½æ•°
    )
    data_summary = get_data_catalog_summary_for_prompt(state)
    todo_section = build_todo_section_for_prompt(state)
    # task_guidance = build_task_guidance_for_prompt(state)
    
    # æ„å»ºå¯¹è¯å†å²ï¼ˆå¦‚æœæœ‰ï¼‰
    chat_history_text = ""
    if state.chat_history:
        chat_history_text = format_chat_history_for_prompt(state.chat_history)
        logger.info(f"[PLANNER] åµŒå…¥å†å²å¯¹è¯ï¼Œå…± {len(state.chat_history)} æ¡æ¶ˆæ¯")
    
    # æ„å»ºç”¨æˆ·ä¿¡æ¯
    user_info = ""
    if state.user_context:
        user_id = state.user_context.get('user_id', 'unknown')
        username = state.user_context.get('username', 'unknown')
        display_name = state.user_context.get('display_name', username)
        user_info = f"\nå½“å‰ç”¨æˆ·: {display_name} (ID: {user_id})\n"
    
    # æ„å»ºç³»ç»Ÿæç¤ºè¯
    system_prompt = f"""# æ™ºèƒ½ä»»åŠ¡è§„åˆ’å™¨

ä½ è´Ÿè´£ç†è§£ç”¨æˆ·éœ€æ±‚å¹¶æ™ºèƒ½åœ°é€‰æ‹©åˆé€‚çš„å“åº”æ–¹å¼ã€‚

## åœºæ™¯è¯†åˆ«
- **æ—¥å¸¸å¯¹è¯**ï¼šé—®å€™ã€é—²èŠç­‰ç®€å•äº¤äº’ï¼Œç›´æ¥å‹å¥½å›å¤å³å¯
- **ç®€å•ä»»åŠ¡**ï¼šå•ä¸€æ˜ç¡®çš„è¯·æ±‚ï¼Œå¯ç›´æ¥æ‰§è¡Œå·¥å…·æˆ–ç»™å‡ºç­”æ¡ˆ
- **å¤æ‚ä»»åŠ¡**ï¼šå¦‚æœè¯„ä¼°ä»»åŠ¡éœ€è¦è¶…è¿‡3æ¬¡å·¥å…·è°ƒç”¨æ‰èƒ½å®Œæˆï¼Œä¼˜å…ˆä½¿ç”¨ TodoGenerator åˆ›å»ºä»»åŠ¡æ¸…å•

## æ ¸å¿ƒèƒ½åŠ›
1. **ç†è§£**: å‡†ç¡®åˆ¤æ–­ç”¨æˆ·æ„å›¾ï¼ˆæ—¥å¸¸å¯¹è¯ vs ä»»åŠ¡éœ€æ±‚ï¼‰
2. **è§„åˆ’**: å¯¹äºå¤æ‚ä»»åŠ¡ï¼Œåˆ†è§£ä¸ºå¯æ‰§è¡Œæ­¥éª¤ï¼ˆä½¿ç”¨TodoGeneratorï¼‰
3. **æ‰§è¡Œ**: è°ƒç”¨åˆé€‚çš„å·¥å…·
4. **å¤ç”¨**: å……åˆ†åˆ©ç”¨å·²æœ‰ç»“æœ
5. **è¯„ä¼°**: åˆ¤æ–­æ˜¯å¦æ»¡è¶³éœ€æ±‚
6. **é€‚åº”**: æ ¹æ®åé¦ˆè°ƒæ•´è®¡åˆ’

## å¯ç”¨å·¥å…·è¯¦æƒ…ä¸ä½¿ç”¨å‚æ•°
{tool_descriptions}

## å…³äºä»»åŠ¡å®Œæˆï¼ˆFINISHï¼‰

- ç»“åˆå†å²æ­¥éª¤ç†è§£å·²ç»è·å–çš„ä¿¡æ¯ï¼Œå¦‚æœè¶³å¤Ÿè¾“å‡ºç¬¦åˆç”¨æˆ·prompté¢„æœŸçš„ç»“æœï¼Œåˆ™é€‰æ‹© FINISH
- ç³»ç»Ÿä¼šè‡ªåŠ¨æ”¶é›†æ‰€æœ‰æ‰§è¡Œå†å²æ•°æ®æ„å»ºä¸Šä¸‹æ–‡ï¼Œæ— éœ€ä½ æä¾›å…·ä½“å†…å®¹
- å¿…é¡»æä¾› output_guidance è¾“å‡ºæŒ‡å¯¼ï¼Œå‘Šè¯‰ç³»ç»Ÿå¦‚ä½•ç»„ç»‡å’Œå‘ˆç°ç­”æ¡ˆ
- è¾“å‡ºèŠ‚ç‚¹ä¼šæ ¹æ®ä»»åŠ¡ç‰¹å¾è‡ªåŠ¨é€‰æ‹©åˆé€‚çš„æ ¼å¼åŒ–å·¥å…·
- ä¸è¦æ»¥ç”¨çŸ¥è¯†åº“å·¥å…·å­˜å‚¨æ•°æ®ï¼Œé™¤éæ˜¯æœ‰ä»·å€¼çš„ä¿¡æ¯æˆ–ç”¨æˆ·çš„åå¥½ã€ä¹ æƒ¯ã€ä¸ªæ€§åŒ–ä¿¡æ¯

## è¾“å‡ºæ ¼å¼

**åªæœ‰ä¸¤ç§æœ‰æ•ˆçš„actionå€¼ï¼š**
1. "CALL_TOOL" - è°ƒç”¨å·¥å…·æ‰§è¡Œä»»åŠ¡
2. "FINISH" - å®Œæˆä»»åŠ¡ï¼ˆå‡†å¤‡äº§å‡ºå›ç­”ï¼‰

å½“ä½¿ç”¨ FINISH æ—¶ï¼š
```json
{{
    "thought": "æ€»ç»“å·²å®Œæˆçš„å·¥ä½œå’Œå…³é”®å‘ç°",
    "action": "FINISH",
    "output_guidance": {{  // é‡è¦ï¼šæä¾›è¾“å‡ºæŒ‡å¯¼
        "key_points": ["è¦ç‚¹1", "è¦ç‚¹2"],  // éœ€è¦å¼ºè°ƒçš„å…³é”®è¦ç‚¹åˆ—è¡¨
        "format_requirements": "æ ¼å¼è¦æ±‚ï¼ˆå¦‚éœ€è¦è¡¨æ ¼ã€åˆ—è¡¨ã€æŠ¥å‘Šç­‰ï¼‰",
        "quality_requirements": "è´¨é‡è¦æ±‚ï¼ˆå¦‚è¯¦ç»†ç¨‹åº¦ã€ä¸“ä¸šæ€§ç­‰ï¼‰",
        "custom_prompt": "ä»»ä½•é¢å¤–çš„è¾“å‡ºæŒ‡å¯¼æˆ–ç‰¹æ®Šè¦æ±‚"
    }}
}}
```

å½“ä½¿ç”¨ CALL_TOOL æ—¶ï¼š
```json
{{
    "thought": "ä½ çš„æ€è€ƒè¿‡ç¨‹",
    "action": "CALL_TOOL",
    "tool_name": "å·¥å…·åç§°",
    "tool_input": {{}},  // å·¥å…·å‚æ•°å¯¹è±¡
    "expected_outcome": "æœŸæœ›çš„æ‰§è¡Œç»“æœ"
}}
```
"""
    
    # æ„å»ºç”¨æˆ·æç¤ºè¯
    user_prompt = f"""## å½“å‰çŠ¶æ€ä¿¡æ¯

### åŸå§‹ä»»åŠ¡
{state._original_task_goal}
{user_info}
{chat_history_text}

### æ‰§è¡Œå†å²
{action_history_prompt}

{data_summary}

{todo_section}

è¯·åŸºäºä»¥ä¸Šä¿¡æ¯å’Œä½ çš„èƒ½åŠ›ï¼Œå†³å®šä¸‹ä¸€æ­¥æœ€åˆé€‚çš„è¡ŒåŠ¨ã€‚"""
    
    return system_prompt, user_prompt
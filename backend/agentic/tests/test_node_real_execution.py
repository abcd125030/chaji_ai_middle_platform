#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
test_node_real_execution.py

çœŸå®æ‰§è¡Œæµ‹è¯•ï¼šä¸ä½¿ç”¨mockï¼ŒçœŸæ­£æµ‹è¯•èŠ‚ç‚¹å†…éƒ¨çš„è¿è¡Œé€»è¾‘ã€‚
è¿™ä¸ªæµ‹è¯•ä¼šçœŸæ­£è°ƒç”¨LLMæœåŠ¡å’Œæ‰§è¡Œå·¥å…·ï¼Œç”¨äºéªŒè¯èŠ‚ç‚¹çš„å®é™…å·¥ä½œæµç¨‹ã€‚

éµå¾ª backend/å•å…ƒæµ‹è¯•è§„èŒƒ.md
"""

import os
import json
import logging
from datetime import datetime
from django.test import TestCase
from django.conf import settings
from django.db import transaction

# å¯¼å…¥éœ€è¦æµ‹è¯•çš„æ¨¡å—
from agentic.nodes.planner import planner_node
from agentic.nodes.reflection import reflection_node
from agentic.core.schemas import RuntimeState, ActionSummary

# å¯¼å…¥é…ç½®ç›¸å…³æ¨¡å—
from router.models import LLMModel
from tools.core.registry import ToolRegistry


class NodeRealExecutionTestCase(TestCase):
    """
    èŠ‚ç‚¹çœŸå®æ‰§è¡Œæµ‹è¯•åŸºç±»
    
    ä¸ä½¿ç”¨ä»»ä½•mockï¼ŒçœŸæ­£è°ƒç”¨LLMæœåŠ¡å’Œå·¥å…·æ‰§è¡Œå™¨ï¼Œ
    æµ‹è¯•èŠ‚ç‚¹å†…éƒ¨çš„å®Œæ•´è¿è¡Œé€»è¾‘ã€‚
    """
    
    @classmethod
    def setUpTestData(cls):
        """
        åœ¨æ•´ä¸ªæµ‹è¯•ç±»è¿è¡Œå‰æ‰§è¡Œä¸€æ¬¡ï¼Œç”¨äºå‡†å¤‡å…±äº«çš„ã€ä¸å˜çš„"èƒŒæ™¯"æ•°æ®ã€‚
        ä»ç”Ÿäº§æ•°æ®åº“è¯»å–çœŸå®é…ç½®ï¼Œå¡«å……åˆ°æµ‹è¯•æ•°æ®åº“ã€‚
        """
        print("\n" + "="*50)
        print(f"[{cls.__name__}] Running setUpTestData: Loading REAL configurations...")
        
        try:
            # ä½¿ç”¨äº‹åŠ¡ç¡®ä¿æ•°æ®åŠ è½½çš„åŸå­æ€§
            with transaction.atomic():
                # ä»çœŸå®é…ç½®ä¸­åŠ è½½LLMæ¨¡å‹é…ç½®
                # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦ç¡®ä¿æµ‹è¯•ç¯å¢ƒæœ‰å¯ç”¨çš„APIå¯†é’¥
                
                # ä»ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶è¯»å–çœŸå®çš„APIé…ç½®
                from django.db import connections
                from django.conf import settings
                
                # å¦‚æœé…ç½®äº†çœŸå®æ•°æ®åº“ï¼Œä»ä¸­è¯»å–é…ç½®
                if hasattr(settings, 'PRODUCTION_DB_ALIAS'):
                    with connections['production'].cursor() as cursor:
                        # è¯»å–LLMæ¨¡å‹é…ç½®
                        cursor.execute("""
                            SELECT v.vendor_id, v.display_name, 
                                   ve.endpoint, ve.service_type,
                                   vk.api_key,
                                   lm.name, lm.model_id, lm.model_type, lm.params
                            FROM router_llmmodel lm
                            JOIN router_vendorendpoint ve ON lm.endpoint_id = ve.id
                            JOIN router_vendor v ON ve.vendor_id = v.id
                            LEFT JOIN router_vendorapikey vk ON vk.vendor_id = v.id
                            WHERE lm.is_active = true
                            LIMIT 5
                        """)
                        
                        for row in cursor.fetchall():
                            # åœ¨æµ‹è¯•æ•°æ®åº“ä¸­åˆ›å»ºç›¸åŒçš„é…ç½®
                            # ... åˆ›å»ºVendor, Endpoint, APIKey, LLMModel
                            pass
                else:
                    # å¦‚æœæ²¡æœ‰ç”Ÿäº§æ•°æ®åº“ï¼Œä½¿ç”¨ç¯å¢ƒå˜é‡åˆ›å»ºæœ€å°é…ç½®
                    from router.vendor_models import Vendor
                    from router.models import VendorEndpoint, VendorAPIKey
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰çœŸå®çš„APIå¯†é’¥
                    qwen_api_key = os.getenv('QWEN_API_KEY')
                    if qwen_api_key:
                        print(f"[{cls.__name__}] Found QWEN_API_KEY in environment")
                        
                        # åˆ›å»ºQwenä¾›åº”å•†é…ç½®
                        qwen_vendor = Vendor.objects.create(
                            vendor_id='qwen',
                            display_name='é€šä¹‰åƒé—®',
                            description='é˜¿é‡Œäº‘é€šä¹‰åƒé—®æ¨¡å‹ï¼ˆçœŸå®APIï¼‰'
                        )
                        
                        qwen_endpoint = VendorEndpoint.objects.create(
                            vendor=qwen_vendor,
                            endpoint=os.getenv('QWEN_ENDPOINT', 'https://dashscope.aliyuncs.com/compatible-mode/v1'),
                            service_type='text'
                        )
                        
                        VendorAPIKey.objects.create(
                            vendor=qwen_vendor,
                            api_key=qwen_api_key,
                            description='çœŸå®Qwen APIå¯†é’¥'
                        )
                        
                        # åˆ›å»ºçœŸå®çš„LLMæ¨¡å‹é…ç½®
                        LLMModel.objects.create(
                            name='qwen-plus',
                            model_id='qwen-plus',
                            model_type='text',
                            endpoint=qwen_endpoint,
                            api_standard='openai',
                            params={
                                'temperature': 0.7,
                                'max_tokens': 2000
                            }
                        )
                        
                        print(f"[{cls.__name__}] Created REAL Qwen configuration")
                    else:
                        print(f"[{cls.__name__}] WARNING: No QWEN_API_KEY found, tests may fail")
                        # åˆ›å»ºä¸€ä¸ªå ä½é…ç½®
                        raise ValueError("éœ€è¦è®¾ç½®QWEN_API_KEYç¯å¢ƒå˜é‡æ‰èƒ½è¿è¡ŒçœŸå®æµ‹è¯•")
                
                print(f"[{cls.__name__}] setUpTestData completed successfully.")
                
        except Exception as e:
            print(f"[{cls.__name__}] CRITICAL: Failed to set up test data: {e}")
            raise
        print("="*50)

    def setUp(self):
        """
        åœ¨æ¯ä¸ª test_ æ–¹æ³•æ‰§è¡Œå‰è¿è¡Œã€‚
        """
        # æ–‡ä»¶å’Œæ—¥å¿—è®¾ç½®
        self.output_dir = os.path.join(settings.BASE_DIR, 'agentic', 'tests', 'outputs')
        os.makedirs(self.output_dir, exist_ok=True)
        
        # ä½¿ç”¨ç¬¦åˆè§„èŒƒçš„æ–‡ä»¶å‘½åæ ¼å¼
        test_method_name = self._testMethodName
        timestamp = datetime.now()
        date_str = timestamp.strftime('%Y%m%d')
        time_str = timestamp.strftime('%H%M%S')
        
        # ç”Ÿæˆç¬¦åˆè§„èŒƒçš„æ–‡ä»¶å
        self.process_filename = f'process-{date_str}-{time_str}-{test_method_name}.json'
        self.log_filename = f'log-{date_str}-{time_str}-{test_method_name}.log'
        self.result_filename = f'result-{date_str}-{time_str}-{test_method_name}.json'
        
        self.setup_logging()
        self.logger.info(f"Test method '{test_method_name}' starting...")
        
        # çŠ¶æ€æ•è·å’Œæ•°æ®è®°å½•
        self.initial_state = self.capture_state("initial")
        self.process_data = {
            "test_info": {
                "name": f"{self.__class__.__name__}.{test_method_name}",
                "start_time": datetime.now().isoformat(),
                "test_type": "REAL_EXECUTION",
                "mock_used": False
            },
            "initial_state": self.initial_state,
            "execution_steps": []
        }
        
        # è®¾ç½®ç¯å¢ƒå˜é‡
        os.environ['ENABLE_PLANNER_CHAIN'] = 'false'  # ä½¿ç”¨åŸå§‹å®ç°

    def setup_logging(self):
        """é…ç½®æ—¥å¿—è®°å½•å™¨"""
        log_file = os.path.join(self.output_dir, self.log_filename)
        
        # é¿å…é‡å¤æ·»åŠ handler
        self.logger = logging.getLogger(self.log_filename)
        if not self.logger.handlers:
            self.logger.setLevel(logging.DEBUG)
            formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
            
            # æ–‡ä»¶å¤„ç†å™¨
            fh = logging.FileHandler(log_file, encoding='utf-8')
            fh.setFormatter(formatter)
            self.logger.addHandler(fh)
            
            # æ§åˆ¶å°å¤„ç†å™¨
            sh = logging.StreamHandler()
            sh.setFormatter(formatter)
            self.logger.addHandler(sh)
            
    def capture_state(self, stage: str):
        """
        æ•è·å½“å‰æ•°æ®åº“å’Œé…ç½®çš„çŠ¶æ€ã€‚
        """
        self.logger.info(f"Capturing {stage} state...")
        
        # æ•è·LLMæ¨¡å‹é…ç½®
        llm_configs = list(LLMModel.objects.values('name', 'model_id', 'model_type'))
        
        # æ•è·å·¥å…·æ³¨å†Œè¡¨çŠ¶æ€
        registry = ToolRegistry()
        tools_snapshot = registry.list_tools_with_details(category='libs')
        
        return {
            "llm_models": llm_configs,
            "registered_tools": len(tools_snapshot),
            "timestamp": datetime.now().isoformat()
        }

    def record_step(self, action, input_data, output_data, **kwargs):
        """è®°å½•æ‰§è¡Œæ­¥éª¤"""
        step_number = len(self.process_data["execution_steps"]) + 1
        step_data = {
            "step": step_number,
            "action": action,
            "input": input_data if isinstance(input_data, (str, dict, list)) else str(input_data),
            "output": output_data if isinstance(output_data, (str, dict, list)) else str(output_data),
            "timestamp": datetime.now().isoformat(),
            **kwargs
        }
        self.process_data["execution_steps"].append(step_data)
        self.logger.info(f"Step {step_number}: {action} recorded.")
    
    def tearDown(self):
        """
        åœ¨æ¯ä¸ª test_ æ–¹æ³•æ‰§è¡Œåè¿è¡Œã€‚
        """
        end_time = datetime.now()
        start_time_iso = self.process_data["test_info"]["start_time"]
        start_time = datetime.fromisoformat(start_time_iso)
        duration = (end_time - start_time).total_seconds()

        self.process_data["test_info"]["end_time"] = end_time.isoformat()
        self.process_data["test_info"]["duration"] = duration
        self.process_data["final_state"] = self.capture_state("final")
        
        # ä¿å­˜è¿‡ç¨‹æ•°æ®
        process_file = os.path.join(self.output_dir, self.process_filename)
        try:
            with open(process_file, 'w', encoding='utf-8') as f:
                json.dump(self.process_data, f, ensure_ascii=False, indent=2, default=str)
            print(f"\nâœ… Process data saved to: {os.path.abspath(process_file)}")
        except Exception as e:
            self.logger.error(f"Failed to write process file: {e}")

        self.logger.info(f"Test method finished. Duration: {duration:.2f}s")
        print(f"\n[INFO] Test outputs saved to directory: {os.path.abspath(self.output_dir)}")


class TestPlannerRealExecution(NodeRealExecutionTestCase):
    """
    æµ‹è¯•PlannerèŠ‚ç‚¹çš„çœŸå®æ‰§è¡Œ
    """
    
    def test_planner_real_planning(self):
        """æµ‹è¯•plannerèŠ‚ç‚¹çœŸå®çš„è§„åˆ’èƒ½åŠ›ï¼ˆè°ƒç”¨çœŸå®LLMï¼‰"""
        self.logger.info("="*50)
        self.logger.info("Testing REAL planner node execution")
        self.logger.info("This test will make REAL API calls!")
        self.logger.info("="*50)
        
        # åˆ›å»ºä¸€ä¸ªç®€å•çš„æµ‹è¯•ä»»åŠ¡
        state = RuntimeState(
            task_goal="è®¡ç®—123åŠ 456çš„ç»“æœ",
            action_summaries=[],
            action_history=[],
            preprocessed_files={},
            todo_items=[],
            full_action_data={}
        )
        
        # è®°å½•åˆå§‹çŠ¶æ€
        self.record_step(
            action="initialize_runtime_state",
            input_data={
                "task_goal": state.task_goal,
                "test_type": "REAL_LLM_CALL"
            },
            output_data={"state_initialized": True}
        )
        
        # èŠ‚ç‚¹é…ç½®
        nodes_map = {
            'planner': {
                'model_name': 'qwen-plus',  # ä½¿ç”¨çœŸå®çš„æ¨¡å‹
                'type': 'planner'
            }
        }
        
        try:
            self.logger.info("Calling planner_node with REAL LLM...")
            
            # çœŸå®è°ƒç”¨plannerèŠ‚ç‚¹ - ä¸ä½¿ç”¨mockï¼
            result = planner_node(
                state=state,
                nodes_map=nodes_map,
                edges_map=None,
                user=None,
                session_id="test_real_session_001"
            )
            
            # è®°å½•çœŸå®çš„LLMå“åº”
            self.record_step(
                action="planner_real_llm_response",
                input_data={"prompt_sent": True},
                output_data=result
            )
            
            # éªŒè¯è¿”å›ç»“æœ
            self.assertIn('current_plan', result)
            plan = result['current_plan']
            
            # è®°å½•LLMçš„çœŸå®å†³ç­–
            self.logger.info(f"\nğŸ¤– LLM Real Decision:")
            self.logger.info(f"  Thought: {plan.thought}")
            self.logger.info(f"  Action: {plan.action}")
            if plan.tool_name:
                self.logger.info(f"  Tool: {plan.tool_name}")
                self.logger.info(f"  Tool Input: {plan.tool_input}")
            
            # éªŒè¯åŸºæœ¬ç»“æ„
            self.assertIsNotNone(plan.thought)
            self.assertIn(plan.action, ['CALL_TOOL', 'FINISH'])
            
            # ä¿å­˜çœŸå®æµ‹è¯•ç»“æœ
            test_result = {
                "test_name": "planner_real_planning",
                "timestamp": datetime.now().isoformat(),
                "llm_model_used": "qwen-plus",
                "task_goal": state.task_goal,
                "llm_response": {
                    "thought": plan.thought,
                    "action": plan.action,
                    "tool_name": plan.tool_name,
                    "tool_input": plan.tool_input if plan.tool_input else None
                },
                "status": "success"
            }
            
            result_file = os.path.join(self.output_dir, self.result_filename)
            with open(result_file, 'w', encoding='utf-8') as f:
                json.dump(test_result, f, ensure_ascii=False, indent=2, default=str)
            
            self.logger.info(f"\nâœ… Real LLM test completed successfully!")
            self.logger.info(f"Result saved to: {result_file}")
            
        except Exception as e:
            self.logger.error(f"Real execution failed: {e}")
            self.record_step(
                action="test_failed",
                input_data={},
                output_data={"error": str(e)}
            )
            # å¦‚æœæ˜¯APIå¯†é’¥é—®é¢˜ï¼Œç»™å‡ºæ˜ç¡®æç¤º
            if "api" in str(e).lower() or "key" in str(e).lower():
                self.logger.error("\nâš ï¸ APIå¯†é’¥å¯èƒ½æœªé…ç½®æˆ–æ— æ•ˆ")
                self.logger.error("è¯·è®¾ç½®ç¯å¢ƒå˜é‡: export QWEN_API_KEY='your-api-key'")
            raise
    
    def test_planner_with_complex_task(self):
        """æµ‹è¯•plannerå¤„ç†å¤æ‚ä»»åŠ¡çš„çœŸå®èƒ½åŠ›"""
        self.logger.info("="*50)
        self.logger.info("Testing planner with COMPLEX task (REAL LLM)")
        self.logger.info("="*50)
        
        # åˆ›å»ºä¸€ä¸ªæ›´å¤æ‚çš„ä»»åŠ¡
        state = RuntimeState(
            task_goal="åˆ†ææœ€è¿‘ä¸‰ä¸ªæœˆçš„é”€å”®æ•°æ®è¶‹åŠ¿ï¼Œæ‰¾å‡ºè¡¨ç°æœ€å¥½çš„äº§å“ç±»åˆ«ï¼Œå¹¶ç»™å‡ºä¸‹å­£åº¦çš„é”€å”®ç­–ç•¥å»ºè®®",
            action_summaries=[],
            action_history=[],
            preprocessed_files={
                'tables': {
                    'q1_sales.xlsx': {
                        'rows': 500,
                        'columns': ['æ—¥æœŸ', 'äº§å“ç±»åˆ«', 'é”€é‡', 'æ”¶å…¥']
                    },
                    'q2_sales.xlsx': {
                        'rows': 600,
                        'columns': ['æ—¥æœŸ', 'äº§å“ç±»åˆ«', 'é”€é‡', 'æ”¶å…¥']
                    }
                }
            },
            todo_items=[],
            full_action_data={}
        )
        
        nodes_map = {
            'planner': {
                'model_name': 'qwen-plus',
                'type': 'planner'
            }
        }
        
        try:
            # çœŸå®è°ƒç”¨planner
            result = planner_node(
                state=state,
                nodes_map=nodes_map,
                edges_map=None,
                user=None,
                session_id="test_complex_001"
            )
            
            plan = result['current_plan']
            
            # åˆ†æLLMçš„è§„åˆ’è´¨é‡
            self.logger.info(f"\nğŸ“Š Complex Task Planning Result:")
            self.logger.info(f"  Thought length: {len(plan.thought)} chars")
            self.logger.info(f"  Action type: {plan.action}")
            
            # æ£€æŸ¥æ˜¯å¦æ­£ç¡®è¯†åˆ«äº†éœ€è¦åˆ†ææ•°æ®
            if plan.action == 'CALL_TOOL':
                self.logger.info(f"  Selected tool: {plan.tool_name}")
                # éªŒè¯æ˜¯å¦é€‰æ‹©äº†åˆé€‚çš„å·¥å…·
                self.assertIsNotNone(plan.tool_name)
            
            # æ£€æŸ¥æ€è€ƒè¿‡ç¨‹çš„è´¨é‡
            thought_keywords = ['é”€å”®', 'æ•°æ®', 'åˆ†æ', 'è¶‹åŠ¿', 'äº§å“']
            thought_quality = sum(1 for kw in thought_keywords if kw in plan.thought)
            self.logger.info(f"  Thought quality score: {thought_quality}/{len(thought_keywords)}")
            
            # è‡³å°‘åº”è¯¥åŒ…å«ä¸€äº›å…³é”®è¯
            self.assertGreater(thought_quality, 0, "LLMåº”è¯¥ç†è§£ä»»åŠ¡å†…å®¹")
            
            self.logger.info(f"\nâœ… Complex task planning test completed!")
            
        except Exception as e:
            self.logger.error(f"Complex task test failed: {e}")
            raise


if __name__ == "__main__":
    # ç›´æ¥è¿è¡Œæµ‹è¯•
    import unittest
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    if not os.getenv('QWEN_API_KEY'):
        print("\n" + "="*60)
        print("âš ï¸  è­¦å‘Šï¼šæœªè®¾ç½®QWEN_API_KEYç¯å¢ƒå˜é‡")
        print("è¿™ä¸ªæµ‹è¯•éœ€è¦çœŸå®çš„APIå¯†é’¥æ‰èƒ½è¿è¡Œ")
        print("è¯·æ‰§è¡Œ: export QWEN_API_KEY='your-api-key'")
        print("="*60 + "\n")
        exit(1)
    
    # åˆ›å»ºæµ‹è¯•å¥—ä»¶
    loader = unittest.TestLoader()
    suite = loader.loadTestsFromTestCase(TestPlannerRealExecution)
    
    # è¿è¡Œæµ‹è¯•
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(suite)
    
    # æ‰“å°ç»“æœæ‘˜è¦
    if result.wasSuccessful():
        print("\n" + "="*50)
        print("âœ… ALL REAL EXECUTION TESTS PASSED!")
        print("="*50)
    else:
        print("\n" + "="*50)
        print("âŒ SOME TESTS FAILED")
        print("="*50)
# 文件预处理功能实现说明

**更新日期：2025-09-22**

## 概述

本文档说明了在 Agentic Graph 系统中实现文件预处理功能的完整流程。该功能可以在接收用户上传的文件后，自动将 docx/pdf 文件转换为 markdown 格式，将 excel 文件转换为 pandas 数据格式，将图片通过视觉模型转换为文字描述，并将预处理后的数据存储在 RuntimeState 中供后续工具使用。

## 实现的功能

### 1. 支持的文件类型
- **docx 文件**: 转换为 markdown 格式的字符串，生成文档摘要
- **pdf 文件**: 转换为 markdown 格式的字符串，生成文档摘要  
- **xlsx/xls 文件**: 转换为 pandas DataFrame 数据（以 JSON 格式存储）
- **jpg/jpeg/png/gif/bmp/webp/svg 图片**: 通过视觉模型（默认 qwen-vl-plus）生成文字描述
- **其他文件**: 保留原始文件路径信息

### 2. 预处理流程

```
用户上传文件 → 文件保存 → 文件预处理 → 数据存储到 RuntimeState → 工具可访问预处理数据
```

## 代码实现

### 1. RuntimeState 结构扩展

在 `backend/agentic/schemas.py` 中扩展了 RuntimeState 类：

```python
class RuntimeState:
    def __init__(self, task_goal: str, preprocessed_files: Optional[Dict[str, Any]] = None):
        self.task_goal: str = task_goal
        self.action_history: List[ActionLog] = []
        self.current_plan: Optional[PlannerOutput] = None
        self.current_tool_output: Optional[Any] = None
        # 新增：存储预处理后的文件数据
        self.preprocessed_files: Dict[str, Any] = preprocessed_files or {
            'documents': {},  # 存储 markdown 格式的文档内容 
            'tables': {},     # 存储表格数据
            'images': {},     # 存储图片的文字描述
            'other_files': [] # 存储其他类型文件的路径信息
        }
```

### 2. 文件预处理逻辑

在 `backend/agentic/services.py` 中添加了 `_preprocess_files` 方法：

```python
def _preprocess_files(self, saved_files: List[Dict[str, str]]) -> Dict[str, Any]:
    """
    预处理上传的文件，将不同类型文件转换为结构化数据：
    - docx/pdf 转换为 markdown 文本
    - excel 转换为表格数据结构
    - 图片通过视觉模型转换为文字描述
    """
    processed_files = {
        'documents': {},  # 存储 markdown 格式的文档内容
        'tables': {},     # 存储 pandas 格式的表格数据
        'images': {},     # 存储图片的文字描述
        'other_files': [] # 存储其他类型文件的路径信息
    }
    
    # 使用专门的预处理工具进行转换
    document_parser = DocumentParserTool()
    excel_processor = ExcelProcessorTool()
    image_processor = ImageProcessorTool()
    
    # ...
```

### 3. GraphExecutor 集成

修改了 `backend/agentic/executor.py` 中的 GraphExecutor：

- 构造函数接收 `preprocessed_files` 参数
- 初始化 RuntimeState 时传入预处理的文件数据
- 工具执行时自动传递预处理数据给工具

### 4. 工具访问预处理数据

工具可以通过 `tool_input['preprocessed_files']` 访问预处理的文件数据：

```python
def execute(self, tool_input: Dict[str, Any]) -> Dict[str, Any]:
    preprocessed_files = tool_input.get('preprocessed_files', {})
    
    # 访问文档数据
    documents = preprocessed_files.get('documents', {})
    
    # 访问表格数据
    tables = preprocessed_files.get('tables', {})
    for table_name, table_info in tables.items():
        df = pd.DataFrame(table_info['data'])  # 转换为 pandas DataFrame
        
    # 访问图片描述
    images = preprocessed_files.get('images', {})
```

## 预处理数据结构

### documents 结构
```json
{
  "uuid-filename.docx": {
    "content": "markdown 格式的文档内容",
    "summary": "文档摘要",
    "name": "report.docx"
  },
  "uuid-filename.pdf": {
    "content": "markdown 格式的文档内容",
    "summary": "文档摘要",
    "name": "document.pdf"
  }
}
```

### tables 结构
```json
{
  "uuid-filename.xlsx": {
    "data": [{"column1": "value1", "column2": "value2"}, ...],
    "row_count": 100,
    "column_count": 5,
    "name": "data.xlsx"
  }
}
```

### images 结构
```json
{
  "uuid-filename.jpg": {
    "description": "这是一张包含...的图片，详细描述内容",
    "name": "photo.jpg",
    "file_path": "/path/to/file",
    "model_used": "qwen-vl-plus"
  }
}
```

### other_files 结构
```json
[
  {
    "path": "/path/to/file",
    "original_name": "archive.zip"
  }
]
```

## 使用的预处理工具

### 1. DocumentParserTool
- 位置: `backend/tools/preprocessors/processors/document_parser.py`
- 功能: 将 .docx 和 .pdf 文件转换为 markdown 格式
- 输入: 文件路径
- 输出: markdown 内容和文档摘要

### 2. ExcelProcessorTool  
- 位置: `backend/tools/preprocessors/processors/excel_processor.py`
- 功能: 将 Excel 文件转换为 JSON 格式的表格数据
- 输入: 文件路径
- 输出: JSON 格式的数据、行数、列数

### 3. ImageProcessorTool
- 位置: `backend/tools/preprocessors/processors/image_processor.py`
- 功能: 使用视觉模型将图片转换为文字描述
- 输入: 文件路径、模型名称（默认 qwen-vl-plus）、提示词
- 输出: 图片的详细文字描述

### 4. PDFParserInternalTool
- 位置: `backend/tools/preprocessors/processors/pdf_parser_internal.py`
- 功能: PDF 文件的底层解析工具
- 被 DocumentParserTool 调用处理 PDF 文件

## 新增的辅助工具

### 1. read_preprocessed_files 工具
- 位置: `backend/tools/advanced/preprocessed_file_reader.py`
- 功能: 读取和分析预处理后的文件数据
- 用途: 方便其他工具访问预处理的文件内容

### 2. test_file_preprocessing 工具
- 位置: `backend/tools/advanced/file_preprocessor_test.py`
- 功能: 测试文件预处理功能是否正常工作
- 用途: 验证预处理数据的完整性和正确性

## 使用示例

### 1. 上传文件并触发预处理

```bash
curl -X POST http://localhost:8000/api/agentic/tasks/ \
  -F "prompt=分析上传的文档、表格和图片" \
  -F "files=@document.docx" \
  -F "files=@report.pdf" \
  -F "files=@data.xlsx" \
  -F "files=@chart.png"
```

### 2. 工具中访问预处理数据

```python
@register_tool("analyze_uploaded_files")
class FileAnalysisTool(BaseTool):
    def execute(self, tool_input: Dict[str, Any]) -> Dict[str, Any]:
        preprocessed_files = tool_input.get('preprocessed_files', {})
        
        # 分析文档内容
        documents = preprocessed_files.get('documents', {})
        for doc_name, doc_data in documents.items():
            content = doc_data['content']  # markdown 格式的字符串
            summary = doc_data['summary']  # 文档摘要
            original_name = doc_data['name']  # 原始文件名
            print(f"文档 {original_name} 内容长度: {len(content)}")
        
        # 分析表格数据
        tables = preprocessed_files.get('tables', {})
        for table_name, table_info in tables.items():
            df = pd.DataFrame(table_info['data'])
            original_name = table_info['name']
            print(f"表格 {original_name} 形状: {df.shape}")
        
        # 分析图片描述
        images = preprocessed_files.get('images', {})
        for img_name, img_data in images.items():
            description = img_data['description']
            original_name = img_data['name']
            model = img_data['model_used']
            print(f"图片 {original_name} 由 {model} 生成描述")
        
        return {"status": "success", "message": "文件分析完成"}
```

## 数据结构变更记录

### 2025-09-22 更新
- **移除** `file_mapping` 字段：不再使用单独的文件名映射表
- **新增** `name` 字段：在 `documents`、`tables`、`images` 的每个条目中直接包含原始文件名
- **优化** 数据访问：相关代码（`schemas.py`、`analyzer.py`）已更新为直接从各数据字段读取 `name` 属性

## 注意事项

1. **性能考虑**: 大文件的预处理可能耗时较长，建议在生产环境中考虑异步处理
2. **错误处理**: 预处理失败的文件会被归类到 `other_files` 中，不会中断整个流程
3. **内存使用**: 预处理后的数据存储在内存中，大量数据可能影响性能
4. **数据持久化**: 预处理的数据通过 checkpoint 机制持久化，任务恢复时会保留预处理结果
5. **图片处理**: 图片文件会先尝试通过视觉模型生成描述，失败则放入 `other_files`
6. **文件命名**: 使用 UUID 作为文件名避免冲突，原始文件名保存在 `name` 字段中

## 测试建议

1. 上传不同格式的文件测试预处理功能
2. 使用 `test_file_preprocessing` 工具验证预处理结果
3. 创建使用预处理数据的自定义工具进行端到端测试
4. 测试大文件和批量文件的处理性能
5. 验证图片描述的准确性和完整性
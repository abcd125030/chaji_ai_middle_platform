# 12要素智能体：构建可靠的LLM应用程序模式
## 作者：Dex Horthy (HumanLayer) - AI工程师演讲

---

## 执行摘要

Dex Horthy 基于对100多位成功在生产环境中构建智能体并创造可观收入的创始人、AI工程师、CTO和从业者的访谈，展示了“12要素智能体：可靠的LLM应用程序模式”。该框架受到Heroku的12要素应用方法论启发，为构建健壮、可维护且可投入生产的LLM驱动软件提供了实用蓝图。

核心见解：**大多数成功的生产AI智能体并不是神奇的自主存在——它们是利用LLM进行特定、受控转换的、工程良好的软件系统。**

---

## 背景与情境

### 问题所在
- 大多数AI智能体实现在70-80%的质量天花板上停滞不前
- 最后20%变成了调试噩梦，团队陷入反向工程提示的困境
- 智能体经常出现幻觉步骤、无限循环或无法达到可靠性标准
- 超越80%往往意味着要从头开始重建

### 研究内容
- 采访了100多位在生产中构建智能体的创业公司创始人和AI工程师
- 重点关注那些将智能体部署到企业并创造10万美元至数百万美元收入的团队
- 在成功的实现中发现了持续的模式
- GitHub仓库登顶Hacker News，正朝着1万星迈进

### 关键发现
成功使用智能体的团队并没有使用最复杂的框架。他们明白**智能体只是软件**，软件工程原则仍然适用。

---

## 12要素智能体框架（实际上是13个要素）

### 核心理念
- LLM最擅长一件事：将自然语言转换为结构化数据（JSON）
- 其他一切都属于常规软件工程
- 将AI智能体视为软件组件，而非神奇的黑盒子
- 应用成熟的工程实践，使其具备生产就绪性

---

## 完整的12 (+1) 要素

### 要素1：自然语言到工具调用
**原则**：使用LLM将自然语言转换为结构化工具调用，然后以确定性方式执行这些工具。

**示例**：
```
自然语言："为Jeff创建一个750美元的付款链接，用于赞助二月份的AI修补匠聚会"

结构化输出：
{
  "function": {
    "name": "create_payment_link",
    "parameters": {
      "amount": 750,
      "customer": "cust_128934ddasf9",
      "product": "prod_8675309",
      "price": "prc_09874329fds",
      "quantity": 1,
      "memo": "嘿 Jeff - 这是二月份AI修补匠聚会的付款链接"
    }
  }
}
```

**实现**：
```python
# LLM接收自然语言并返回结构化JSON
# 你的确定性代码处理执行
if tool_call.name == "create_payment_link":
    result = stripe.payment_links.create(**tool_call.parameters)
    return result
```

---

### 要素2：掌控你的提示（Prompt）
**原则**：将提示作为一流代码自行编写，而不是依赖不透明的智能体框架。

**关键点**：
- 将提示视为代码，而非一次性字符串
- 对提示和模板进行版本控制
- 避免使用“黑盒”提示工程库
- 保持完全的可见性和控制力

**重要性**：
> “你的提示是你应用逻辑与LLM之间的主要接口。”

**益处**：
- 对智能体行为的完全控制
- 易于测试和评估
- 透明的调试过程
- 快速迭代能力

---

### 要素3：掌控你的上下文窗口
**原则**：完全控制发送给LLM的上下文，而不是依赖标准消息格式。

**核心见解**：
> “在任何给定点，你在智能体中输入LLM的内容都是‘到目前为止发生了什么，下一步是什么’”

**上下文工程包括**：
- 提示和指令
- 检索到的文档（RAG）
- 过去的状态、工具调用和结果
- 相关对话历史
- 结构化输出指令

**自定义上下文格式示例**：
不使用标准消息格式，而是创建优化结构：
```python
context = {
    "current_state": {...},
    "available_tools": [...],
    "constraints": {...},
    "history": [...],
    "objective": "..."
}
```

---

### 要素4：工具是结构化输出
**原则**：将工具调用视为触发确定性代码的结构化JSON输出，而非魔法函数。

**模式**：
1. LLM输出结构化JSON
2. 确定性代码执行适当操作
3. 结果反馈到上下文中

**示例**：
```python
class CreateIssue:
    intent: "create_issue"
    issue: Issue

class SearchIssues:
    intent: "search_issues"
    query: str
    what_youre_looking_for: str

# 执行
if nextStep.intent == 'create_payment_link':
    stripe.paymentlinks.create(nextStep.parameters)
elif nextStep.intent == 'wait_for_a_while': 
    # 以不同方式处理
else:
    # 处理未知工具
```

---

### 要素5：统一执行状态与业务状态
**原则**：避免将业务状态与执行状态分离——尽可能保持统一。

**定义**：
- **执行状态**：当前步骤、下一步、等待状态、重试次数
- **业务状态**：工作流中发生的事情（消息、工具调用、结果）

**益处**：你可以从上下文窗口推断所有执行状态，从而简化架构。

---

### 要素6：通过简单API启动/暂停/恢复
**原则**：构建简单的API，允许智能体从外部触发器启动、暂停和恢复。

**要求**：
- 通过API轻松启动
- 在长时间操作期间能够暂停
- 无需深度集成即可通过webhook恢复
- 清晰的状态管理

**用例**：
- 等待人工批准
- 长时间运行的操作
- 外部事件触发器

---

### 要素7：通过工具调用与人类联系
**原则**：将人类交互视为另一个结构化工具调用，而非特殊情况。

**实现**：
```python
class RequestHumanInput:
    intent: "request_human_input"
    question: str
    context: str
    options: Options

# 在智能体循环中
if nextStep.intent == 'request_human_input':
    thread.events.append({
        type: 'human_input_requested',
        data: nextStep
    })
    await notify_human(nextStep, thread_id)
    return  # 中断循环并等待响应
```

---

### 要素8：掌控你的控制流
**原则**：构建自定义控制结构，而不是依赖通用智能体循环。

**自定义控制示例**：
- 请求澄清 → 中断循环，等待人工
- 获取数据 → 附加到上下文，继续
- 高风险操作 → 请求批准

**益处**：
- 结果的摘要/缓存
- 对输出的LLM判断
- 上下文窗口管理
- 日志和指标记录
- 速率限制
- 持久的休眠/暂停

---

### 要素9：将错误压缩到上下文窗口
**原则**：将错误转化为LLM的上下文，以实现自我修复行为。

**实现**：
```python
consecutive_errors = 0
while True:
    try:
        result = await handle_next_step(thread, next_step)
        consecutive_errors = 0
    except Exception as e:
        consecutive_errors += 1
        if consecutive_errors < 3:
            thread["events"].append({
                "type": 'error',
                "data": format_error(e),
            })
            # LLM可以看到错误并进行调整
        else:
            # 升级处理或中断
```

**益处**：
- 自我修复能力
- 尽管出现故障也能继续运行
- 更好的错误处理

---

### 要素10：小型、专注的智能体
**原则**：构建最多处理3-20步的智能体，而不是庞大的单一智能体。

**核心见解**：
> “随着上下文的增长，LLM更容易迷失或失去焦点”

**益处**：
1. 可管理的上下文窗口
2. 职责清晰
3. 更好的可靠性
4. 更容易测试
5. 更好的调试体验

**面向未来**：随着LLM的改进，智能体范围可以逐渐扩大，同时保持可靠性。

---

### 要素11：从任何地方触发
**原则**：使智能体能够通过Slack、电子邮件、短信等方式触发和响应。

**益处**：
- 在用户所在之处与其互动
- 启用事件驱动的智能体
- 支持需要人工监督的高风险操作
- 创建数字同事

**用例**：
- 外循环智能体（工作数小时，在关键点联系人类）
- 跨平台通信
- 异步工作流

---

### 要素12：让你的智能体成为无状态归约器
**原则**：将智能体设计为纯函数，接收先前状态并返回新状态。

**函数式方法**：
```
agent(current_state, new_input) → new_state
```

**益处**：
- 可预测的行为
- 易于测试
- 清晰的状态管理
- 函数式编程原则

---

### 要素13（附录）：预取你可能需要的所有上下文
**原则**：主动地、确定性地收集上下文，而不是让LLM去获取。

**关键引述**：
> “如果你已经知道你希望模型调用哪些工具，那就确定性地调用它们，让模型去做困难的部分——弄清楚如何使用它们的输出。”

**演进过程**：
1. ❌ 要求模型单独获取上下文
2. ✅ 预取上下文并包含在提示中
3. ✅✅ 将上下文检索完全集成到工作流中

---

## 实现理念

### 核心原则

1. **JSON提取是基础**
   - LLM能做的最神奇的事情是将自然语言转换为结构化数据
   - 其他一切都属于常规软件工程

2. **上下文工程 > 提示工程**
   - 关注进入上下文窗口的内容
   - 上下文的质量决定输出的质量

3. **智能体是软件组件**
   - 并非神奇的自主存在
   - 应用标准工程实践
   - 保持模块化、可观察性和健壮性

4. **从小处着手，逐步扩展**
   - 从聚焦的微型智能体开始
   - 随着LLM能力的提升逐步扩展范围
   - 始终保持可靠性

---

## 现实世界影响

### 成功指标
- 框架在Hacker News上占据首页一整天
- GitHub仓库正朝着1万星迈进
- 被构建百万美元收入智能体的团队采用
- 得到了100多位生产从业者的一致认可

### 关键差异化因素
成功使用智能体的团队并没有使用最复杂的框架。他们明白：
- 智能体只是软件
- 工程原则仍然适用
- 可靠性来自良好的架构，而非魔法

---

## 实际应用

### 何时使用此框架
- 构建生产AI系统
- 需要超过80%成功率的可靠性
- 部署到企业客户
- 创造可观收入
- 需要可审计性和控制力

### 你将实现什么
- 突破70-80%的质量天花板
- 避免调试噩梦
- 构建可维护的系统
- 创建可靠的生产智能体
- 充满信心地扩展

---

## 历史背景：软件简史

该框架包含了一个关于软件演化的哲学视角：

1. **传统的“循环直到解决”方法是有缺陷的**
   - 上下文窗口限制导致智能体“迷失”
   - 即使窗口更长，聚焦的提示效果更好

2. **微智能体是解决方案**
   - 小型、专注的工作流组件
   - 在更大的确定性系统内
   - 战略性AI集成，而非替代

3. **有效智能体的核心组件**：
   - 定义行为和工具的提示
   - 用于工具处理的Switch语句
   - 积累的上下文跟踪
   - 用于进程推进的控制循环

---

## 关键要点

### 对于工程师
1. **掌控你的技术栈**：不要将关键组件外包给不透明的框架
2. **以模式思考**：将12个要素作为模式应用，而非僵化规则
3. **从简单开始**：从基本实现开始，根据需要扩展
4. **衡量一切**：可观察性对生产系统至关重要

### 对于组织
1. **AI原生 ≠ 抛弃工程学**：不要抛弃数十年的智慧
2. **渐进式采用**：从小型智能体开始，逐步扩大范围
3. **关注可靠性**：99%的可靠性胜过100%的自主性
4. **人在回路**：从一开始就为人工监督设计

### 底线
> “将高质量AI软件交到客户手中最快的方法是，从智能体构建中采用小型、模块化的概念，并将它们融入现有产品中。”

---

## 资源与参考

### 官方资源
- **GitHub仓库**：[github.com/humanlayer/12-factor-agents](https://github.com/humanlayer/12-factor-agents)
- **HumanLayer**：[humanlayer.dev](https://humanlayer.dev)
- **作者**：Dex Horthy (@dexhorthy)

### 演讲
- AI工程师世界博览会 (2024年6月)
- 生产中的智能体 2025
- MLOps社区视频

### 社区
- Hacker News讨论（占据首页一整天）
- 多篇博客分析和实现
- 不断壮大的从业者生态系统

---

## 关于作者

**Dex Horthy**是HumanLayer的创始人，该平台用于构建具有人工监督的可靠AI智能体。他的工作基于：
- 对100多位生产从业者的访谈
- 构建和部署生产智能体
- 分析成功实现的模式
- 为人类-智能体交互创建工具

---

## 结论

12要素智能体框架代表了我们思考AI智能体方式的范式转变。它并不追求神奇的自主系统，而是倡导精心设计的软件，战略性地利用LLM。

信息很明确：**用成熟的工程实践构建可靠的系统，而非依赖未来AI魔法的承诺。**

正如Dex Horthy强调的那样：“大多数在生产中真正成功的‘AI智能体’根本不是神奇的自主存在——它们主要是工程良好的传统软件，LLM能力在关键点被小心翼翼地融入其中。”

该框架为加入成功生产AI实现的行列提供了蓝图，超越80%的天花板，为客户交付真正的价值。

---

*最后更新：基于截至2025年的演讲和文档*
*框架版本：1.0（包含13个要素）*
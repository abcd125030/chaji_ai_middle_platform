#!/usr/bin/env python3
"""
åŸºäºQwen3-VL-Plusçš„æ™ºèƒ½è¯­ä¹‰åˆ†å‰²ç³»ç»Ÿ

æ–‡ä»¶åŠŸèƒ½ï¼š
ä½¿ç”¨é€šä¹‰åƒé—®VL-Plusæ¨¡å‹å¯¹PDFé¡µé¢è¿›è¡Œæ™ºèƒ½è¯­ä¹‰åˆ†å‰²ï¼Œè¯†åˆ«å¹¶æå–é¡µé¢ä¸­çš„å›¾ç¤ºåŒºåŸŸã€‚

è¾“å…¥ï¼š
- PDFæ–‡æ¡£è·¯å¾„
- é¡µé¢ç¼–å·
- DPIè®¾ç½®ï¼ˆé»˜è®¤300ï¼‰
- å¯é€‰ï¼šåˆ†å‰²ç¤ºä¾‹å›¾ç‰‡ï¼ˆç»¿è‰²æ¡†æ ‡è®°éœ€è¦æå–çš„åŒºåŸŸï¼‰

è¾“å‡ºï¼š
- åŸå§‹é¡µé¢å›¾åƒ
- åˆå§‹åˆ†å‰²å¯è§†åŒ– + å…ƒæ•°æ®
- æ ¡å‡†ååˆ†å‰²å¯è§†åŒ– + å…ƒæ•°æ®ï¼ˆå¦‚æœéœ€è¦ï¼‰
- æœ€ç»ˆç‰ˆæœ¬å¯è§†åŒ–
- å„ä¸ªè¯†åˆ«åŒºåŸŸçš„ç‹¬ç«‹å›¾åƒæ–‡ä»¶
- å®Œæ•´å…ƒæ•°æ®JSON

æ ¸å¿ƒç‰¹ç‚¹ï¼š
- ç›´æ¥ä½¿ç”¨VLæ¨¡å‹è¿›è¡Œè¯­ä¹‰ç†è§£ï¼Œæ— éœ€SAMé¢„åˆ†å‰²
- ç²¾å‡†è¯†åˆ«å›¾è¡¨ã€æµç¨‹å›¾ã€ç¤ºæ„å›¾ç­‰è§†è§‰å…ƒç´ 
- å®éªŒæ€§è‡ªæˆ‘æ ¡å‡†åŠŸèƒ½ï¼šVLæ¨¡å‹æ£€æŸ¥è‡ªå·±çš„è¾“å‡ºå¹¶è°ƒæ•´
- è¾“å‡ºç»“æ„åŒ–çš„åŒºåŸŸä¿¡æ¯ï¼Œä¾¿äºåç»­æ–‡æ¡£é‡æ„

æç¤ºè¯è®¾è®¡åŸç†ï¼š
1. ç›®æ ‡æ˜ç¡®ï¼šåªæå–éœ€è¦ä»¥å›¾ç‰‡å½¢å¼ä¿ç•™åœ¨Markdownä¸­çš„è§†è§‰å†…å®¹
2. åæ ‡ç³»ç»Ÿï¼šä½¿ç”¨ç™¾åˆ†æ¯”ï¼ˆ0-100ï¼‰è€Œéå›ºå®šæ¯”ä¾‹ï¼Œé€‚åº”ä»»æ„å®½é«˜æ¯”å›¾åƒ
3. ç¤ºä¾‹å¼•å¯¼ï¼šæ”¯æŒæä¾›ç»¿è‰²æ¡†æ ‡è®°çš„ç¤ºä¾‹å›¾ï¼Œè®©æ¨¡å‹å­¦ä¹ åˆ†å‰²ç²’åº¦
4. æ’é™¤çº¯æ–‡æœ¬ï¼šæ˜ç¡®å‘ŠçŸ¥æ¨¡å‹ä¸æå–çº¯æ–‡æœ¬æ®µè½ï¼ˆé€šè¿‡å…¶ä»–æ–¹å¼æå–ï¼‰

å®éªŒè®°å½•ï¼ˆ2025-09-30ï¼‰ï¼š
- åˆç‰ˆé—®é¢˜ï¼šå…¨é¡µåˆ†å‰²ï¼Œäº§ç”Ÿè¿‡å¤šæ— å…³segments
- æ”¹è¿›1ï¼šæ˜ç¡®"åªæå–è§†è§‰å…ƒç´ "ï¼Œå‡å°‘çº¯æ–‡æœ¬æå–
- æ”¹è¿›2ï¼šä»1000å•ä½ç³»ç»Ÿæ”¹ä¸ºç™¾åˆ†æ¯”ç³»ç»Ÿï¼Œè§£å†³å®½é«˜æ¯”é—®é¢˜
- æ”¹è¿›3ï¼šæ·»åŠ è‡ªæˆ‘æ ¡å‡†æµç¨‹ï¼ŒVLæ¨¡å‹æŸ¥çœ‹å¯è§†åŒ–ç»“æœå¹¶ä¿®æ­£åæ ‡
- æ ¡å‡†å®éªŒç»“æœï¼šä¸ç¨³å®šï¼Œå¯èƒ½è®©ç»“æœå˜å·®ï¼ˆå·²é»˜è®¤ç¦ç”¨ï¼‰
  é—®é¢˜ï¼šVLæ¨¡å‹çœ‹åˆ°å¯è§†åŒ–ååè€Œæ‰©å¤§äº†è¾¹ç•Œæ¡†ï¼ŒåŒ…å«äº†æ— å…³å†…å®¹
  åŸå› ï¼šå¯èƒ½æ˜¯æç¤ºè¯ä¸å¤Ÿç²¾ç¡®ï¼Œæˆ–æ¨¡å‹å¯¹"å®Œæ•´æ€§"ç†è§£æœ‰åå·®
"""

import os
import sys
import json
import base64
from pathlib import Path
from typing import List, Dict, Optional, Tuple, Any
from dataclasses import dataclass, asdict
from datetime import datetime
import numpy as np
import cv2
from PIL import Image, ImageDraw, ImageFont
import io
import fitz  # PyMuPDF
from openai import OpenAI

# å°è¯•åŠ è½½dotenv
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass

# é…ç½®
DASHSCOPE_API_KEY = os.getenv("DASHSCOPE_API_KEY")
DASHSCOPE_BASE_URL = "https://dashscope.aliyuncs.com/compatible-mode/v1"

@dataclass
class ImageRegion:
    """å›¾åƒåŒºåŸŸå®šä¹‰"""
    id: int
    type: str  # diagram, chart, table, formula, photo, text_block, title
    description: str
    bbox: List[int]  # [x, y, width, height] in pixels
    confidence: float
    semantic_label: str  # è¯­ä¹‰æ ‡ç­¾ï¼Œå¦‚"architecture_diagram", "flow_chart"ç­‰
    
    def to_dict(self) -> Dict:
        return asdict(self)
    
    def to_dict_with_percentage(self, image_width: int, image_height: int) -> Dict:
        """è¿”å›åŒ…å«ç™¾åˆ†æ¯”åæ ‡çš„å­—å…¸"""
        data = asdict(self)
        # æ·»åŠ ç™¾åˆ†æ¯”åæ ‡ [å·¦ä¸Šx%, å·¦ä¸Šy%, å³ä¸‹x%, å³ä¸‹y%]
        data['bbox_percentage'] = [
            round(self.bbox[0] * 100.0 / image_width, 2),  # å·¦ä¸Šè§’x%
            round(self.bbox[1] * 100.0 / image_height, 2),  # å·¦ä¸Šè§’y%
            round((self.bbox[0] + self.bbox[2]) * 100.0 / image_width, 2),  # å³ä¸‹è§’x%
            round((self.bbox[1] + self.bbox[3]) * 100.0 / image_height, 2)  # å³ä¸‹è§’y%
        ]
        return data

class Qwen3VLSegmentation:
    """åŸºäºQwen3-VL-Plusçš„è¯­ä¹‰åˆ†å‰²å™¨"""
    
    def __init__(self, api_key: Optional[str] = None, model: str = "qwen3-vl-plus", 
                 example_image_path: Optional[str] = None):
        """
        åˆå§‹åŒ–åˆ†å‰²å™¨
        
        Args:
            api_key: DashScope APIå¯†é’¥
            model: ä½¿ç”¨çš„æ¨¡å‹åç§°
            example_image_path: åˆ†å‰²ç¤ºä¾‹å›¾ç‰‡è·¯å¾„
        """
        self.api_key = api_key or DASHSCOPE_API_KEY
        self.model = model
        
        # è®¾ç½®ç¤ºä¾‹å›¾ç‰‡è·¯å¾„ï¼ˆé»˜è®¤è·¯å¾„ï¼‰
        # æ³¨æ„ï¼šç¤ºä¾‹å›¾ç‰‡å¯èƒ½ä¼šå¹²æ‰°æŸäº›é¡µé¢çš„è¯†åˆ«ï¼Œå»ºè®®è°¨æ…ä½¿ç”¨
        self.example_image_path = example_image_path
        # å¦‚æœæ²¡æœ‰æ˜ç¡®æŒ‡å®šç¤ºä¾‹å›¾ç‰‡ï¼Œé»˜è®¤ä¸ä½¿ç”¨
        # self.example_image_path = example_image_path or "/Users/chagee/Repos/chagee-utils/ppt_extractor/segmentation_example.png"
        
        if not self.api_key:
            raise ValueError("DASHSCOPE_API_KEY not found in environment variables")
        
        # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯ï¼ˆå…¼å®¹æ¨¡å¼ï¼‰
        self.client = OpenAI(
            api_key=self.api_key,
            base_url=DASHSCOPE_BASE_URL
        )
        
        print(f"âœ… Initialized Qwen3-VL Segmentation with model: {self.model}")
        
        # æ£€æŸ¥ç¤ºä¾‹å›¾ç‰‡æ˜¯å¦å­˜åœ¨
        if self.example_image_path and Path(self.example_image_path).exists():
            print(f"ğŸ“ Using segmentation example: {self.example_image_path}")
        elif self.example_image_path:
            print(f"â„¹ï¸ No example image found at: {self.example_image_path}")
        else:
            print("â„¹ï¸ No example image specified")
    
    def pdf_to_image(self, pdf_path: str, page_number: int = 1, dpi: int = 300) -> np.ndarray:
        """
        å°†PDFé¡µé¢è½¬æ¢ä¸ºå›¾åƒ
        
        Args:
            pdf_path: PDFæ–‡ä»¶è·¯å¾„
            page_number: é¡µé¢ç¼–å·ï¼ˆä»1å¼€å§‹ï¼‰
            dpi: è¾“å‡ºå›¾åƒçš„DPI
            
        Returns:
            å›¾åƒæ•°ç»„
        """
        doc = fitz.open(pdf_path)
        page = doc[page_number - 1]
        
        zoom = dpi / 72.0
        mat = fitz.Matrix(zoom, zoom)
        pix = page.get_pixmap(matrix=mat, alpha=False)
        
        img_data = pix.tobytes("png")
        img = Image.open(io.BytesIO(img_data))
        image = np.array(img)
        
        doc.close()
        return image
    
    def analyze_image_regions(self, image: np.ndarray) -> List[ImageRegion]:
        """
        ä½¿ç”¨Qwen3-VL-Plusåˆ†æå›¾åƒå¹¶è¯†åˆ«åŒºåŸŸ
        
        Args:
            image: è¾“å…¥å›¾åƒæ•°ç»„
            
        Returns:
            è¯†åˆ«å‡ºçš„åŒºåŸŸåˆ—è¡¨
        """
        # å°†å›¾åƒç¼–ç ä¸ºbase64
        _, buffer = cv2.imencode('.png', cv2.cvtColor(image, cv2.COLOR_RGB2BGR))
        img_base64 = base64.b64encode(buffer).decode('utf-8')
        
        # å‡†å¤‡æ¶ˆæ¯å†…å®¹
        message_content = []
        
        # å¦‚æœæœ‰ç¤ºä¾‹å›¾ç‰‡ï¼Œå…ˆæ·»åŠ ç¤ºä¾‹
        if self.example_image_path and Path(self.example_image_path).exists():
            try:
                # è¯»å–ç¤ºä¾‹å›¾ç‰‡
                example_img = Image.open(self.example_image_path)
                example_np = np.array(example_img)
                
                # ç¼–ç ç¤ºä¾‹å›¾ç‰‡
                _, example_buffer = cv2.imencode('.png', cv2.cvtColor(example_np, cv2.COLOR_RGB2BGR))
                example_base64 = base64.b64encode(example_buffer).decode('utf-8')
                
                # æ·»åŠ ç¤ºä¾‹å›¾ç‰‡å’Œè¯´æ˜
                message_content.extend([
                    {
                        "type": "text",
                        "text": "å‚è€ƒè¿™ä¸ªåˆ†å‰²ç¤ºä¾‹å›¾ï¼Œå›¾ä¸­ä»…ç»¿è‰²æ¡†ä»£è¡¨ç¬¦åˆåˆ†å‰²çš„åŒºåŸŸï¼Œç†è§£å¦‚ä½•è¯†åˆ«å’Œåˆ†å‰²æ–‡æ¡£ä¸­çš„ä¸åŒåŒºåŸŸï¼š"
                    },
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/png;base64,{example_base64}"
                        }
                    },
                    {
                        "type": "text",
                        "text": "ç°åœ¨è¯·æŒ‰ç…§ç¤ºä¾‹å›¾ä¸­ç»¿è‰²æ¡†çš„ç²¾ç¡®è¾¹ç•Œæ–¹å¼ï¼Œåˆ†æä¸‹é¢è¿™å¼ å›¾ç‰‡ã€‚æ³¨æ„ï¼šç»¿è‰²æ¡†ç´§å¯†è´´åˆå†…å®¹ï¼Œæ²¡æœ‰å¤šä½™ç©ºç™½ã€‚è¯·ç”¨åŒæ ·ç²¾ç¡®çš„æ–¹å¼æå–è§†è§‰å…ƒç´ åŒºåŸŸï¼š"
                    }
                ])
                print("   ğŸ“ Added segmentation example to request")
            except Exception as e:
                print(f"   âš ï¸ Failed to load example image: {e}")
        
        # æ·»åŠ è¦åˆ†æçš„å›¾ç‰‡
        message_content.append({
            "type": "image_url",
            "image_url": {
                "url": f"data:image/png;base64,{img_base64}"
            }
        })
        
        # æ·»åŠ æç¤ºè¯
        prompt = self._build_segmentation_prompt()
        message_content.append({
            "type": "text",
            "text": prompt
        })
        
        try:
            print("ğŸ“¡ Calling Qwen3-VL-Plus for semantic segmentation...")
            
            # è°ƒç”¨APIè¿›è¡Œåˆ†æ
            completion = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "user",
                        "content": message_content
                    }
                ],
                temperature=0.1,  # ä½æ¸©åº¦ä»¥è·å¾—æ›´ä¸€è‡´çš„ç»“æœ
                stream=False
            )
            
            response = completion.choices[0].message.content
            print(f"âœ… Received response: {len(response)} characters")
            
            # æ‰“å°åŸå§‹å“åº”ä»¥ä¾¿è°ƒè¯•
            print("\nğŸ“ Raw VL Model Response:")
            print("-" * 60)
            print(response[:1000] if len(response) > 1000 else response)  # æ‰“å°å‰1000ä¸ªå­—ç¬¦
            if len(response) > 1000:
                print(f"... (truncated, total {len(response)} chars)")
            print("-" * 60)
            
            # è§£æå“åº”
            regions = self._parse_vl_response(response, image.shape)
            print(f"ğŸ“Š Identified {len(regions)} regions")
            
            return regions
            
        except Exception as e:
            print(f"âŒ Error calling Qwen3-VL: {e}")
            return []
    
    def _build_segmentation_prompt(self) -> str:
        """æ„å»ºè¯­ä¹‰åˆ†å‰²çš„æç¤ºè¯"""
        base_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æ¡£è§†è§‰å†…å®¹æå–ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯ä»æ–‡æ¡£é¡µé¢ä¸­è¯†åˆ«å’Œæå–æœ‰è§†è§‰ä»·å€¼çš„å†…å®¹åŒºåŸŸï¼Œç”¨äºåç»­çš„Markdownæ–‡æ¡£é‡æ„ã€‚

æ ¸å¿ƒä»»åŠ¡ï¼š
åªæå–åŒ…å«è§†è§‰å…ƒç´ çš„å†…å®¹åŒºåŸŸï¼Œè¿™äº›åŒºåŸŸåœ¨è½¬æ¢ä¸ºMarkdownæ—¶éœ€è¦ä»¥å›¾ç‰‡å½¢å¼ä¿ç•™ã€‚

éœ€è¦æå–çš„å†…å®¹ï¼ˆä»…é™ä»¥ä¸‹ç±»å‹ï¼‰ï¼š
1. ç¤ºæ„å›¾åŒºåŸŸï¼ˆdiagram_areaï¼‰ï¼šåŒ…å«ç¤ºæ„å›¾ã€æ¶æ„å›¾ã€æµç¨‹å›¾åŠå…¶ç›¸å…³è¯´æ˜æ–‡å­—
2. å›¾è¡¨åŒºåŸŸï¼ˆchart_areaï¼‰ï¼šåŒ…å«æ•°æ®å›¾è¡¨ï¼ˆæŸ±çŠ¶å›¾ã€é¥¼å›¾ã€æŠ˜çº¿å›¾ç­‰ï¼‰åŠå…¶æ ‡é¢˜è¯´æ˜
3. å›¾æ–‡æ··åˆåŒºåŸŸï¼ˆimage_text_areaï¼‰ï¼šåŒ…å«äº§å“å›¾ç‰‡ã€è®¾å¤‡ç…§ç‰‡ç­‰ä¸å…¶è¯´æ˜æ–‡å­—çš„ç»„åˆ
4. è¡¨æ ¼åŒºåŸŸï¼ˆtable_areaï¼‰ï¼šåŒ…å«ç»“æ„åŒ–è¡¨æ ¼ï¼Œç‰¹åˆ«æ˜¯å¸¦å›¾æ ‡æˆ–è§†è§‰å…ƒç´ çš„è¡¨æ ¼
5. å…¬å¼åŒºåŸŸï¼ˆformula_areaï¼‰ï¼šæ•°å­¦å…¬å¼ã€åŒ–å­¦å¼ç­‰ç‰¹æ®Šç¬¦å·å†…å®¹

ä¸è¦æå–çš„å†…å®¹ï¼ˆå¿½ç•¥ä»¥ä¸‹å†…å®¹ï¼‰ï¼š
- çº¯æ–‡æœ¬æ®µè½ï¼ˆè¿™äº›ä¼šé€šè¿‡å…¶ä»–æ–¹å¼æå–ï¼‰
- å•ç‹¬çš„æ ‡é¢˜æ–‡å­—
- é¡µçœ‰é¡µè„š
- é¡µç 
- å•çº¯çš„æ–‡å­—åˆ—è¡¨ï¼ˆæ²¡æœ‰å›¾æ ‡æˆ–è§†è§‰å…ƒç´ çš„ï¼‰

å…³é”®åŸåˆ™ï¼š
- æ¯ä¸ªåŒºåŸŸå¿…é¡»æ˜¯ä¸€ä¸ªå®Œæ•´çš„è§†è§‰å•å…ƒï¼ˆå›¾+å…¶ç›´æ¥ç›¸å…³çš„è¯´æ˜æ–‡å­—ï¼‰
- ç´§å¯†è´´åˆå†…å®¹è¾¹ç•Œï¼Œä¸è¦åŒ…å«å¤šä½™çš„ç©ºç™½æˆ–æ— å…³å†…å®¹
- å¦‚æœæœ‰å¤šä¸ªç‹¬ç«‹çš„è§†è§‰ç»„ï¼Œåº”è¯¥åˆ†åˆ«æå–ï¼Œè€Œä¸æ˜¯åˆå¹¶æˆä¸€ä¸ªå¤§åŒºåŸŸ
- åˆ¤æ–­æ ‡å‡†ï¼šè¿™ä¸ªåŒºåŸŸæ˜¯å¦éœ€è¦ä»¥å›¾ç‰‡å½¢å¼ä¿ç•™åœ¨æœ€ç»ˆçš„Markdownä¸­ï¼Ÿ
- è¾¹ç•Œè¦ç²¾ç¡®ï¼šåªæ¡†é€‰å®é™…å†…å®¹ï¼Œä¸è¦ä¸ºäº†"å®‰å…¨"è€Œæ‰©å¤§èŒƒå›´

è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ç»“æœï¼Œä½¿ç”¨åƒç´ åæ ‡ï¼š

{
    "bbox_format": "left_top_x, left_top_y, right_bottom_x, right_bottom_y",
    "regions": [
        {
            "id": 1,
            "type": "image_text_area", 
            "description": "è®¾å¤‡ä»‹ç»åŒºåŸŸï¼ŒåŒ…å«6ä¸ªè®¾å¤‡å›¾ç‰‡åŠå…¶åŠŸèƒ½è¯´æ˜",
            "bbox": [100, 200, 900, 600],
            "bbox_meaning": {
                "left_top_x": 100,
                "left_top_y": 200,
                "right_bottom_x": 900,
                "right_bottom_y": 600
            },
            "confidence": 0.95,
            "semantic_label": "equipment_showcase"
        }
    ]
}

é‡è¦çš„åæ ‡ç³»ç»Ÿè¯´æ˜ï¼š
- ä½¿ç”¨åƒç´ åæ ‡ï¼ˆç»å¯¹åæ ‡ï¼‰
- bboxæ ¼å¼å¿…é¡»æ˜¯ï¼š[left_top_x, left_top_y, right_bottom_x, right_bottom_y]
  - left_top_x: å·¦ä¸Šè§’çš„xåƒç´ åæ ‡
  - left_top_y: å·¦ä¸Šè§’çš„yåƒç´ åæ ‡  
  - right_bottom_x: å³ä¸‹è§’çš„xåƒç´ åæ ‡ï¼ˆå¿…é¡»å¤§äºleft_top_xï¼‰
  - right_bottom_y: å³ä¸‹è§’çš„yåƒç´ åæ ‡ï¼ˆå¿…é¡»å¤§äºleft_top_yï¼‰
- æ¯ä¸ªåŒºåŸŸå¿…é¡»åŒæ—¶æä¾›bboxå’Œbbox_meaningå­—æ®µï¼Œç¡®ä¿åæ ‡å«ä¹‰æ¸…æ™°
- ç²¾ç¡®æ€§è¦æ±‚ï¼š
  - è¾¹ç•Œè¦ç´§è´´å†…å®¹ï¼Œä¸è¦åŒ…å«å¤§ç‰‡ç©ºç™½
  - å®å¯ç¨å¾®ç´§ä¸€ç‚¹ï¼Œä¹Ÿä¸è¦æ¡†å¾—å¤ªæ¾
- ç¤ºä¾‹ï¼ˆå‡è®¾å›¾åƒå°ºå¯¸2250x3250ï¼‰ï¼š
  - é¡µé¢ä¸­å¤®çš„å°å›¾ï¼šbbox=[900, 1300, 1350, 1950]ï¼Œå…¶ä¸­left_top=(900,1300), right_bottom=(1350,1950)
  - å·¦ä¸Šè§’çš„å†…å®¹å—ï¼šbbox=[100, 150, 1125, 1000]ï¼Œå…¶ä¸­left_top=(100,150), right_bottom=(1125,1000)"""
        
        # å¦‚æœæœ‰ç¤ºä¾‹å›¾ç‰‡ï¼Œæ·»åŠ é¢å¤–è¯´æ˜
        if self.example_image_path and Path(self.example_image_path).exists():
            base_prompt += """

é‡è¦å‚è€ƒï¼š
   - è¯·ä»”ç»†å‚è€ƒä¸Šé¢æä¾›çš„åˆ†å‰²ç¤ºä¾‹å›¾
   - å…³é”®ï¼šç¤ºä¾‹å›¾ä¸­åªæœ‰ç»¿è‰²æ¡†æ ‡è®°çš„åŒºåŸŸæ‰æ˜¯éœ€è¦æå–çš„è§†è§‰å†…å®¹åŒºåŸŸ
   - å…¶ä»–é¢œè‰²ï¼ˆå¦‚çº¢è‰²æ¡†ï¼‰æ˜¯æ–‡æ¡£åŸæœ‰å†…å®¹ï¼Œä¸æ˜¯åˆ†å‰²æ ‡è®°
   - å­¦ä¹ ç¤ºä¾‹ä¸­æ˜¯å¦‚ä½•è¯†åˆ«"å®Œæ•´çš„è§†è§‰å•å…ƒ"çš„
   - æ³¨æ„ï¼šåªæå–é‚£äº›åŒ…å«å›¾ç‰‡ã€å›¾è¡¨ã€è¡¨æ ¼ç­‰è§†è§‰å…ƒç´ çš„åŒºåŸŸï¼Œçº¯æ–‡æœ¬ä¸è¦æå–"""
        
        base_prompt += "\n\nè¯·ç›´æ¥è¿”å›JSONæ ¼å¼çš„ç»“æœï¼Œä¸è¦åŒ…å«å…¶ä»–è§£é‡Šæ–‡å­—ã€‚"
        
        return base_prompt
    
    def _parse_vl_response(self, response: str, image_shape: Tuple) -> List[ImageRegion]:
        """
        è§£æVLæ¨¡å‹çš„å“åº”
        
        Args:
            response: æ¨¡å‹å“åº”æ–‡æœ¬
            image_shape: åŸå§‹å›¾åƒå°ºå¯¸
            
        Returns:
            è§£æåçš„åŒºåŸŸåˆ—è¡¨
        """
        regions = []
        height, width = image_shape[:2]
        
        try:
            # å°è¯•æå–JSON
            import re
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                data = json.loads(json_match.group())
            else:
                data = json.loads(response)
            
            # é¦–å…ˆæ£€æŸ¥æ˜¯å¦æœ‰bbox_formatå­—æ®µ
            bbox_format = data.get('bbox_format', '')
            print(f"   Declared bbox format: {bbox_format}" if bbox_format else "   No bbox format declared")
            
            # è§£æåŒºåŸŸæ•°æ®
            for idx, region_data in enumerate(data.get('regions', [])):
                bbox = region_data.get('bbox', [0, 0, 100, 100])
                bbox_meaning = region_data.get('bbox_meaning', None)
                
                # å¦‚æœæä¾›äº†bbox_meaningï¼Œä½¿ç”¨å®ƒæ¥ç¡®ä¿æ­£ç¡®ç†è§£åæ ‡
                if bbox_meaning:
                    print(f"   Using bbox_meaning for region {idx+1}")
                    # ä»bbox_meaningæ„å»ºæ­£ç¡®çš„bboxï¼ˆæ€»æ˜¯[x,y,width,height]æ ¼å¼ï¼‰
                    left_x = bbox_meaning.get('left_top_x', bbox[0])
                    left_y = bbox_meaning.get('left_top_y', bbox[1])
                    right_x = bbox_meaning.get('right_bottom_x', bbox[2])
                    right_y = bbox_meaning.get('right_bottom_y', bbox[3])
                    
                    # è®¡ç®—å®½é«˜
                    width_calc = right_x - left_x
                    height_calc = right_y - left_y
                    
                    # éªŒè¯åæ ‡åˆç†æ€§
                    if width_calc <= 0 or height_calc <= 0:
                        print(f"   âš ï¸ Invalid bbox_meaning: width={width_calc}, height={height_calc}")
                        # å›é€€åˆ°åŸå§‹bboxå¤„ç†
                    else:
                        # ä½¿ç”¨ä»bbox_meaningè®¡ç®—çš„å€¼
                        bbox = [left_x, left_y, width_calc, height_calc]
                        print(f"   Calculated from meaning: x={left_x}, y={left_y}, w={width_calc}, h={height_calc}")
                
                # æ™ºèƒ½åˆ¤æ–­åæ ‡ç±»å‹
                # å¦‚æœä»»ä½•å€¼å¤§äº100ï¼Œè¯´æ˜æ¨¡å‹å¯èƒ½è¿”å›äº†ç»å¯¹åæ ‡
                if any(val > 100 for val in bbox):
                    # å¯èƒ½æ˜¯ç»å¯¹åæ ‡
                    if any(val > 1000 for val in bbox):
                        # è‚¯å®šæ˜¯ç»å¯¹åæ ‡ï¼ˆåƒç´ å€¼ï¼‰
                        # åˆ¤æ–­æ˜¯[x, y, width, height]è¿˜æ˜¯[x1, y1, x2, y2]æ ¼å¼
                        is_x2y2_format = False
                        
                        # æ£€æŸ¥ç¬¬3ä¸ªå€¼æ˜¯å¦å¯èƒ½æ˜¯x2ï¼ˆå³è¾¹ç•Œï¼‰
                        if bbox[2] > bbox[0] and bbox[2] <= width:
                            potential_width = bbox[2] - bbox[0]
                            if potential_width > 100 and potential_width < width:
                                is_x2y2_format = True
                        
                        # æ£€æŸ¥ç¬¬4ä¸ªå€¼æ˜¯å¦å¯èƒ½æ˜¯y2ï¼ˆä¸‹è¾¹ç•Œï¼‰
                        if bbox[3] > bbox[1] and bbox[3] <= height:
                            potential_height = bbox[3] - bbox[1]
                            if potential_height > 100 and potential_height < height:
                                is_x2y2_format = True
                        
                        if is_x2y2_format:
                            # [å·¦ä¸Šx, å·¦ä¸Šy, å³ä¸‹x, å³ä¸‹y]æ ¼å¼ï¼ˆç»å¯¹åæ ‡ï¼‰
                            abs_bbox = [
                                int(bbox[0]),  # å·¦ä¸Šè§’xåæ ‡
                                int(bbox[1]),  # å·¦ä¸Šè§’yåæ ‡
                                int(bbox[2] - bbox[0]),  # å®½åº¦ = å³ä¸‹x - å·¦ä¸Šx
                                int(bbox[3] - bbox[1])   # é«˜åº¦ = å³ä¸‹y - å·¦ä¸Šy
                            ]
                            print(f"   Detected absolute [å·¦ä¸Šx,å·¦ä¸Šy,å³ä¸‹x,å³ä¸‹y]: {bbox} -> w={abs_bbox[2]}, h={abs_bbox[3]}")
                        else:
                            # [x, y, width, height]æ ¼å¼
                            abs_bbox = [int(v) for v in bbox]
                            print(f"   Detected absolute [x,y,w,h]: {bbox}")
                    else:
                        # 100-1000èŒƒå›´ï¼Œå¯èƒ½æ˜¯æ—§çš„1000å•ä½ç³»ç»Ÿ
                        print(f"   Warning: coordinates in 100-1000 range, treating as 1000-unit system")
                        abs_bbox = [
                            int(bbox[0] * width / 1000),
                            int(bbox[1] * height / 1000),
                            int(bbox[2] * width / 1000),
                            int(bbox[3] * height / 1000)
                        ]
                else:
                    # ç™¾åˆ†æ¯”åæ ‡ï¼ˆ0-100èŒƒå›´ï¼‰- è™½ç„¶æˆ‘ä»¬ç°åœ¨è¦æ±‚åƒç´ åæ ‡ï¼Œä½†ä»ä¿ç•™å¯¹ç™¾åˆ†æ¯”çš„æ”¯æŒ
                    abs_bbox = [
                        int(bbox[0] * width / 100),   # å·¦ä¸Šè§’xåæ ‡è½¬åƒç´ 
                        int(bbox[1] * height / 100),  # å·¦ä¸Šè§’yåæ ‡è½¬åƒç´ 
                        int((bbox[2] - bbox[0]) * width / 100),   # å®½åº¦ = (å³ä¸‹è§’x - å·¦ä¸Šè§’x)
                        int((bbox[3] - bbox[1]) * height / 100)   # é«˜åº¦ = (å³ä¸‹è§’y - å·¦ä¸Šè§’y)
                    ]
                    print(f"   Detected percentage [å·¦ä¸Šx,å·¦ä¸Šy,å³ä¸‹x,å³ä¸‹y]: {bbox}% -> w={abs_bbox[2]}, h={abs_bbox[3]}")
                
                # ç¡®ä¿è¾¹ç•Œæ¡†åœ¨å›¾åƒèŒƒå›´å†…
                abs_bbox[0] = max(0, min(abs_bbox[0], width))
                abs_bbox[1] = max(0, min(abs_bbox[1], height))
                abs_bbox[2] = max(1, min(abs_bbox[2], width - abs_bbox[0]))
                abs_bbox[3] = max(1, min(abs_bbox[3], height - abs_bbox[1]))
                
                region = ImageRegion(
                    id=region_data.get('id', idx + 1),
                    type=region_data.get('type', 'unknown'),
                    description=region_data.get('description', ''),
                    bbox=abs_bbox,
                    confidence=region_data.get('confidence', 0.5),
                    semantic_label=region_data.get('semantic_label', 'general')
                )
                regions.append(region)
                
                print(f"  Region {region.id}: {region.type} - {region.description[:50]}...")
                
        except json.JSONDecodeError as e:
            print(f"âš ï¸ Failed to parse JSON response: {e}")
            print(f"Response preview: {response[:200]}...")
            
            # é™çº§å¤„ç†ï¼šå°è¯•åŸºäºå¯å‘å¼æ–¹æ³•
            regions = self._fallback_segmentation(image_shape)
        
        return regions
    
    def _fallback_segmentation(self, image_shape: Tuple) -> List[ImageRegion]:
        """
        é™çº§çš„å¯å‘å¼åˆ†å‰²æ–¹æ³•
        
        Args:
            image_shape: å›¾åƒå°ºå¯¸
            
        Returns:
            åŸºç¡€çš„åŒºåŸŸåˆ†å‰²
        """
        height, width = image_shape[:2]
        
        # ç®€å•çš„ç½‘æ ¼åˆ†å‰²ä½œä¸ºé™çº§æ–¹æ¡ˆ
        regions = []
        
        # ä¸ŠåŠéƒ¨åˆ†å¯èƒ½æ˜¯æ ‡é¢˜
        regions.append(ImageRegion(
            id=1,
            type="title",
            description="Page header/title area",
            bbox=[0, 0, width, int(height * 0.15)],
            confidence=0.3,
            semantic_label="header"
        ))
        
        # ä¸»ä½“å†…å®¹åŒºåŸŸ
        regions.append(ImageRegion(
            id=2,
            type="mixed",
            description="Main content area",
            bbox=[0, int(height * 0.15), width, int(height * 0.85)],
            confidence=0.3,
            semantic_label="content"
        ))
        
        print("âš ï¸ Using fallback segmentation (2 regions)")
        return regions
    
    def calibrate_regions_with_vl(self, image: np.ndarray, visualization: np.ndarray, 
                                   regions: List[ImageRegion]) -> List[ImageRegion]:
        """
        ä½¿ç”¨VLæ¨¡å‹æ ¡å‡†å·²è¯†åˆ«çš„åŒºåŸŸåæ ‡
        
        Args:
            image: åŸå§‹å›¾åƒ
            visualization: å¸¦æ ‡æ³¨æ¡†çš„å¯è§†åŒ–å›¾åƒ
            regions: åˆå§‹è¯†åˆ«çš„åŒºåŸŸåˆ—è¡¨
            
        Returns:
            æ ¡å‡†åçš„åŒºåŸŸåˆ—è¡¨
        """
        print("\nğŸ”§ Calibrating regions with VL model...")
        
        # å°†å¯è§†åŒ–å›¾åƒç¼–ç ä¸ºbase64
        _, buffer = cv2.imencode('.png', cv2.cvtColor(visualization, cv2.COLOR_RGB2BGR))
        vis_base64 = base64.b64encode(buffer).decode('utf-8')
        
        # æ„å»ºæ ¡å‡†æç¤ºè¯
        calibration_prompt = f"""è¯·ä»”ç»†æŸ¥çœ‹è¿™ä¸ªå¸¦æœ‰è“è‰²è¾¹ç•Œæ¡†çš„æ ‡æ³¨å›¾åƒã€‚

å½“å‰æ ‡æ³¨çš„åŒºåŸŸä¿¡æ¯å¦‚ä¸‹ï¼š
{json.dumps([{
    'id': r.id,
    'type': r.type,
    'description': r.description,
    'current_bbox_percentage': [
        round(r.bbox[0] * 100 / image.shape[1], 1),  # x%
        round(r.bbox[1] * 100 / image.shape[0], 1),  # y%
        round(r.bbox[2] * 100 / image.shape[1], 1),  # width%
        round(r.bbox[3] * 100 / image.shape[0], 1)   # height%
    ]
} for r in regions], indent=2, ensure_ascii=False)}

è¯·æ£€æŸ¥æ¯ä¸ªè“è‰²æ¡†æ˜¯å¦å‡†ç¡®æ¡†é€‰äº†å¯¹åº”çš„å†…å®¹åŒºåŸŸã€‚å¦‚æœå‘ç°åå·®ï¼Œè¯·æä¾›æ ¡æ­£åçš„åæ ‡ã€‚

ä»»åŠ¡è¦æ±‚ï¼š
1. ä»”ç»†è§‚å¯Ÿæ¯ä¸ªè“è‰²æ¡†çš„ä½ç½®å’Œå¤§å°
2. åˆ¤æ–­æ˜¯å¦å®Œæ•´åŒ…å«äº†æè¿°ä¸­çš„å†…å®¹
3. å¦‚æœè¾¹ç•Œä¸å‡†ç¡®ï¼Œæä¾›è°ƒæ•´åçš„ç™¾åˆ†æ¯”åæ ‡

è¾“å‡ºæ ¼å¼ï¼ˆä½¿ç”¨ç™¾åˆ†æ¯”åæ ‡0-100ï¼‰ï¼š
{{
    "calibrated_regions": [
        {{
            "id": 1,
            "needs_adjustment": true/false,
            "reason": "æ¡†é€‰èŒƒå›´åå¤§/åå°/ä½ç½®åç§»ç­‰",
            "new_bbox": [x%, y%, width%, height%]
        }}
    ]
}}

æ³¨æ„ï¼š
- åªæœ‰å½“è¾¹ç•Œæ˜æ˜¾ä¸å‡†ç¡®æ—¶æ‰éœ€è¦è°ƒæ•´
- new_bboxä½¿ç”¨ç™¾åˆ†æ¯”ï¼ˆ0-100ï¼‰
- å¦‚æœä¸éœ€è¦è°ƒæ•´ï¼Œnew_bboxå¯ä»¥çœç•¥"""
        
        try:
            # è°ƒç”¨VLæ¨¡å‹è¿›è¡Œæ ¡å‡†
            completion = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/png;base64,{vis_base64}"
                                }
                            },
                            {
                                "type": "text",
                                "text": calibration_prompt
                            }
                        ]
                    }
                ],
                temperature=0.1,
                stream=False
            )
            
            response = completion.choices[0].message.content
            print(f"   Received calibration response: {len(response)} chars")
            
            # è§£ææ ¡å‡†å“åº”
            import re
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                calibration_data = json.loads(json_match.group())
                
                # åº”ç”¨æ ¡å‡†
                calibrated_regions = []
                height, width = image.shape[:2]
                
                for region in regions:
                    # æŸ¥æ‰¾å¯¹åº”çš„æ ¡å‡†ä¿¡æ¯
                    calibration = None
                    for cal in calibration_data.get('calibrated_regions', []):
                        if cal.get('id') == region.id:
                            calibration = cal
                            break
                    
                    if calibration and calibration.get('needs_adjustment', False):
                        # éœ€è¦è°ƒæ•´
                        new_bbox_pct = calibration.get('new_bbox')
                        if new_bbox_pct:
                            # è½¬æ¢ç™¾åˆ†æ¯”åˆ°ç»å¯¹åæ ‡
                            new_bbox = [
                                int(new_bbox_pct[0] * width / 100),
                                int(new_bbox_pct[1] * height / 100),
                                int(new_bbox_pct[2] * width / 100),
                                int(new_bbox_pct[3] * height / 100)
                            ]
                            
                            # åˆ›å»ºæ–°çš„åŒºåŸŸå¯¹è±¡
                            calibrated_region = ImageRegion(
                                id=region.id,
                                type=region.type,
                                description=region.description,
                                bbox=new_bbox,
                                confidence=region.confidence,
                                semantic_label=region.semantic_label
                            )
                            calibrated_regions.append(calibrated_region)
                            
                            print(f"   âœ… Region {region.id} calibrated: {calibration.get('reason', 'adjusted')}")
                            print(f"      Old bbox%: [{round(region.bbox[0]*100/width,1)}, {round(region.bbox[1]*100/height,1)}, {round(region.bbox[2]*100/width,1)}, {round(region.bbox[3]*100/height,1)}]")
                            print(f"      New bbox%: {new_bbox_pct}")
                        else:
                            calibrated_regions.append(region)
                    else:
                        # ä¸éœ€è¦è°ƒæ•´
                        calibrated_regions.append(region)
                        print(f"   âœ“ Region {region.id} - no adjustment needed")
                
                return calibrated_regions
                
        except Exception as e:
            print(f"   âš ï¸ Calibration failed: {e}")
            print(f"   Using original regions without calibration")
            return regions
        
        return regions
    
    def extract_region(self, image: np.ndarray, region: ImageRegion) -> np.ndarray:
        """
        ä»å›¾åƒä¸­æå–æŒ‡å®šåŒºåŸŸ
        
        Args:
            image: åŸå§‹å›¾åƒ
            region: åŒºåŸŸå®šä¹‰
            
        Returns:
            è£å‰ªçš„åŒºåŸŸå›¾åƒ
        """
        x, y, w, h = region.bbox
        
        # ç¡®ä¿åæ ‡åœ¨æœ‰æ•ˆèŒƒå›´å†…
        x = max(0, x)
        y = max(0, y)
        x_end = min(image.shape[1], x + w)
        y_end = min(image.shape[0], y + h)
        
        # è£å‰ªåŒºåŸŸ
        cropped = image[y:y_end, x:x_end]
        
        return cropped
    
    def visualize_regions(self, image: np.ndarray, regions: List[ImageRegion]) -> np.ndarray:
        """
        åˆ›å»ºåŒºåŸŸå¯è§†åŒ–
        
        Args:
            image: åŸå§‹å›¾åƒ
            regions: åŒºåŸŸåˆ—è¡¨
            
        Returns:
            å¸¦æ ‡æ³¨çš„å¯è§†åŒ–å›¾åƒ
        """
        vis_image = image.copy()
        
        # ä¸ºæ¯ä¸ªåŒºåŸŸç±»å‹å®šä¹‰é¢œè‰²
        type_colors = {
            'diagram_area': (255, 100, 100),      # çº¢è‰² - ç¤ºæ„å›¾åŒºåŸŸ
            'chart_area': (100, 255, 100),        # ç»¿è‰² - å›¾è¡¨åŒºåŸŸ
            'image_text_area': (100, 100, 255),   # è“è‰² - å›¾æ–‡æ··åˆåŒºåŸŸ
            'table_area': (255, 255, 100),        # é»„è‰² - è¡¨æ ¼åŒºåŸŸ
            'formula_area': (255, 100, 255),      # ç´«è‰² - å…¬å¼åŒºåŸŸ
            'unknown': (200, 200, 200)            # æµ…ç° - æœªçŸ¥ç±»å‹
        }
        
        # ç»˜åˆ¶æ¯ä¸ªåŒºåŸŸ
        for region in regions:
            x, y, w, h = region.bbox
            color = type_colors.get(region.type, (200, 200, 200))
            
            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            cv2.rectangle(vis_image, (x, y), (x + w, y + h), color, 3)
            
            # ç»˜åˆ¶åŠé€æ˜å¡«å……
            overlay = vis_image.copy()
            cv2.rectangle(overlay, (x, y), (x + w, y + h), color, -1)
            cv2.addWeighted(overlay, 0.2, vis_image, 0.8, 0, vis_image)
            
            # æ·»åŠ æ ‡ç­¾èƒŒæ™¯
            label = f"#{region.id} {region.type} ({region.confidence:.2f})"
            font_scale = 0.6
            thickness = 2
            (text_width, text_height), baseline = cv2.getTextSize(
                label, cv2.FONT_HERSHEY_SIMPLEX, font_scale, thickness
            )
            
            # æ ‡ç­¾èƒŒæ™¯æ¡†
            label_y = max(y - 5, text_height + 5)
            cv2.rectangle(vis_image, 
                         (x, label_y - text_height - 5),
                         (x + text_width + 10, label_y + 5),
                         color, -1)
            
            # æ·»åŠ æ–‡å­—
            cv2.putText(vis_image, label,
                       (x + 5, label_y),
                       cv2.FONT_HERSHEY_SIMPLEX,
                       font_scale, (255, 255, 255), thickness)
            
            # æ·»åŠ æè¿°ï¼ˆå¦‚æœä¸å¤ªé•¿ï¼‰
            if region.description and len(region.description) < 50:
                desc_y = label_y + text_height + 15
                cv2.putText(vis_image, region.description[:40],
                           (x + 5, min(desc_y, y + h - 5)),
                           cv2.FONT_HERSHEY_SIMPLEX,
                           0.4, color, 1)
        
        return vis_image
    
    def process_page(self, pdf_path: str, page_number: int = 1, 
                     output_dir: Optional[str] = None, dpi: int = 300) -> Dict[str, Any]:
        """
        å¤„ç†PDFé¡µé¢å¹¶è¿›è¡Œè¯­ä¹‰åˆ†å‰²
        
        Args:
            pdf_path: PDFæ–‡ä»¶è·¯å¾„
            page_number: é¡µé¢ç¼–å·
            output_dir: è¾“å‡ºç›®å½•
            dpi: å›¾åƒDPI
            
        Returns:
            å¤„ç†ç»“æœå­—å…¸
        """
        print(f"\n{'='*60}")
        print(f"Processing: {pdf_path}, Page {page_number}")
        print(f"{'='*60}\n")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        if output_dir is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_dir = f"./ppt/{timestamp}_qwen3_vl_segmentation"
        
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        print(f"ğŸ“ Output directory: {output_path}")
        
        # 1. è½¬æ¢PDFä¸ºå›¾åƒ
        print("\n1ï¸âƒ£ Converting PDF to image...")
        image = self.pdf_to_image(pdf_path, page_number, dpi)
        print(f"   Image size: {image.shape[1]} x {image.shape[0]} pixels")
        
        # ä¿å­˜åŸå§‹å›¾åƒ
        original_path = output_path / f"page{page_number:03d}_original.png"
        Image.fromarray(image).save(original_path)
        print(f"   Saved: {original_path}")
        
        # 2. ä½¿ç”¨qwen3-vl-plusè¿›è¡Œè¯­ä¹‰åˆ†å‰²
        print("\n2ï¸âƒ£ Performing semantic segmentation with Qwen3-VL-Plus...")
        regions = self.analyze_image_regions(image)
        
        if not regions:
            print("   âš ï¸ No regions identified")
            return {
                'success': False,
                'message': 'No regions identified',
                'page_number': page_number,
                'output_dir': str(output_path)
            }
        
        # 3. åˆ›å»ºåˆå§‹å¯è§†åŒ–
        print("\n3ï¸âƒ£ Creating visualization...")
        visualization = self.visualize_regions(image, regions)
        
        # ä¿å­˜åˆå§‹ç‰ˆæœ¬
        vis_path_initial = output_path / f"page{page_number:03d}_visualization_initial.png"
        Image.fromarray(visualization).save(vis_path_initial)
        print(f"   Saved initial: {vis_path_initial}")
        
        # ä¿å­˜åˆå§‹å…ƒæ•°æ®
        initial_metadata = {
            'stage': 'initial',
            'regions': [region.to_dict() for region in regions]
        }
        initial_metadata_path = output_path / f"page{page_number:03d}_metadata_initial.json"
        with open(initial_metadata_path, 'w', encoding='utf-8') as f:
            json.dump(initial_metadata, f, indent=2, ensure_ascii=False)
        print(f"   Saved initial metadata: {initial_metadata_path}")
        
        # 3.5. å®éªŒæ€§åŠŸèƒ½ï¼šä½¿ç”¨VLæ¨¡å‹æ ¡å‡†åŒºåŸŸåæ ‡
        # âš ï¸ å®éªŒç»“æœï¼ˆ2025-09-30ï¼‰ï¼šæ ¡å‡†åŠŸèƒ½ä¸ç¨³å®šï¼Œå¯èƒ½è®©ç»“æœå˜å·®
        # å»ºè®®ç¦ç”¨ï¼šæ³¨é‡Šæ‰ä¸‹é¢çš„ä»£ç å—
        # print("\n3.5ï¸âƒ£ Experimental: Calibrating with VL model...")
        # calibrated_regions = self.calibrate_regions_with_vl(image, visualization, regions)
        
        # æš‚æ—¶ç¦ç”¨æ ¡å‡†ï¼Œç›´æ¥ä½¿ç”¨åˆå§‹ç»“æœ
        calibrated_regions = regions
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å˜åŒ–
        regions_changed = False
        for orig, calib in zip(regions, calibrated_regions):
            if orig.bbox != calib.bbox:
                regions_changed = True
                break
        
        if regions_changed:
            print("   ğŸ“ Regions were calibrated, saving calibrated version...")
            regions = calibrated_regions
            
            # ç”Ÿæˆæ ¡å‡†åçš„å¯è§†åŒ–
            visualization_calibrated = self.visualize_regions(image, regions)
            vis_path_calibrated = output_path / f"page{page_number:03d}_visualization_calibrated.png"
            Image.fromarray(visualization_calibrated).save(vis_path_calibrated)
            print(f"   Saved calibrated: {vis_path_calibrated}")
            
            # ä¿å­˜æ ¡å‡†åçš„å…ƒæ•°æ®
            calibrated_metadata = {
                'stage': 'calibrated',
                'regions': [region.to_dict() for region in regions]
            }
            calibrated_metadata_path = output_path / f"page{page_number:03d}_metadata_calibrated.json"
            with open(calibrated_metadata_path, 'w', encoding='utf-8') as f:
                json.dump(calibrated_metadata, f, indent=2, ensure_ascii=False)
            print(f"   Saved calibrated metadata: {calibrated_metadata_path}")
            
            # ä½¿ç”¨æ ¡å‡†åçš„ç‰ˆæœ¬ä½œä¸ºæœ€ç»ˆç‰ˆæœ¬
            visualization = visualization_calibrated
        else:
            print("   âœ“ No calibration needed, regions are already accurate")
            # ä½¿ç”¨åˆå§‹ç‰ˆæœ¬ä½œä¸ºæœ€ç»ˆç‰ˆæœ¬
            visualization = visualization
        
        # ä¿å­˜æœ€ç»ˆç‰ˆæœ¬ï¼ˆä¾¿äºä½¿ç”¨ï¼‰
        vis_path = output_path / f"page{page_number:03d}_visualization.png"
        Image.fromarray(visualization).save(vis_path)
        print(f"   Saved final: {vis_path}")
        
        # 4. æå–å’Œä¿å­˜å„ä¸ªåŒºåŸŸ
        print("\n4ï¸âƒ£ Extracting individual regions...")
        extracted_files = []
        
        for region in regions:
            # æå–åŒºåŸŸå›¾åƒ
            region_image = self.extract_region(image, region)
            
            # ç”Ÿæˆæ–‡ä»¶å
            safe_type = region.type.replace(' ', '_').lower()
            filename = f"page{page_number:03d}_region{region.id:02d}_{safe_type}.png"
            filepath = output_path / filename
            
            # ä¿å­˜åŒºåŸŸå›¾åƒ
            Image.fromarray(region_image).save(filepath)
            extracted_files.append(filename)
            
            print(f"   Region {region.id}: {region.type} -> {filename}")
            if region.description:
                print(f"      Description: {region.description}")
        
        # 5. ä¿å­˜å…ƒæ•°æ®
        print("\n5ï¸âƒ£ Saving metadata...")
        
        # æ„å»ºè¾“å‡ºæ–‡ä»¶åˆ—è¡¨
        output_files = {
            'original': str(original_path.name),
            'visualization_initial': str(vis_path_initial.name),
            'metadata_initial': str(initial_metadata_path.name),
            'visualization_final': str(vis_path.name),
            'regions': extracted_files
        }
        
        # å¦‚æœè¿›è¡Œäº†æ ¡å‡†ï¼Œæ·»åŠ æ ¡å‡†æ–‡ä»¶
        if regions_changed:
            output_files['visualization_calibrated'] = str(vis_path_calibrated.name)
            output_files['metadata_calibrated'] = str(calibrated_metadata_path.name)
            calibration_status = 'calibrated'
        else:
            calibration_status = 'no_calibration_needed'
        
        metadata = {
            'source_pdf': str(Path(pdf_path).name),
            'page_number': page_number,
            'processing_time': datetime.now().isoformat(),
            'calibration_status': calibration_status,
            'image_size': {
                'width': image.shape[1],
                'height': image.shape[0]
            },
            'dpi': dpi,
            'total_regions': len(regions),
            'regions': [region.to_dict() for region in regions],
            'output_files': output_files
        }
        
        metadata_path = output_path / f"page{page_number:03d}_metadata.json"
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)
        print(f"   Saved: {metadata_path}")
        
        # 6. ç”Ÿæˆæ‘˜è¦æŠ¥å‘Š
        print("\n" + "="*60)
        print("âœ… Processing Complete!")
        print(f"ğŸ“Š Identified {len(regions)} regions:")
        
        # ç»Ÿè®¡å„ç±»å‹åŒºåŸŸ
        type_counts = {}
        for region in regions:
            type_counts[region.type] = type_counts.get(region.type, 0) + 1
        
        for type_name, count in sorted(type_counts.items()):
            print(f"   - {type_name}: {count} region(s)")
        
        print(f"\nğŸ“ Results saved in: {output_path}")
        print(f"   - Original image: {original_path.name}")
        print(f"   - Visualization: {vis_path.name}")
        print(f"   - Extracted regions: {len(extracted_files)} files")
        print(f"   - Metadata: {metadata_path.name}")
        print("="*60)
        
        return {
            'success': True,
            'page_number': page_number,
            'output_dir': str(output_path),
            'total_regions': len(regions),
            'regions': [region.to_dict() for region in regions],
            'files': {
                'original': str(original_path),
                'visualization': str(vis_path),
                'metadata': str(metadata_path),
                'regions': [str(output_path / f) for f in extracted_files]
            }
        }


def main():
    """ä¸»å‡½æ•°ï¼šå‘½ä»¤è¡Œæ¥å£"""
    if len(sys.argv) < 2:
        print("Usage: python qwen3_vl_segmentation.py <PDF_file> [page_number] [--output-dir DIR]")
        print("\nExamples:")
        print("  python qwen3_vl_segmentation.py document.pdf")
        print("  python qwen3_vl_segmentation.py document.pdf 2")
        print("  python qwen3_vl_segmentation.py document.pdf 1 --output-dir ./results")
        print("\nNote: Requires DASHSCOPE_API_KEY environment variable")
        sys.exit(1)
    
    # è§£æå‚æ•°
    pdf_path = sys.argv[1]
    page_number = 1
    output_dir = None
    
    # è§£æé¡µç 
    if len(sys.argv) > 2 and sys.argv[2].isdigit():
        page_number = int(sys.argv[2])
    
    # è§£æè¾“å‡ºç›®å½•
    if "--output-dir" in sys.argv:
        idx = sys.argv.index("--output-dir")
        if idx + 1 < len(sys.argv):
            output_dir = sys.argv[idx + 1]
    
    # æ£€æŸ¥æ–‡ä»¶å­˜åœ¨
    if not Path(pdf_path).exists():
        print(f"âŒ Error: File not found - {pdf_path}")
        sys.exit(1)
    
    # æ£€æŸ¥APIå¯†é’¥
    if not os.getenv("DASHSCOPE_API_KEY"):
        print("âŒ Error: DASHSCOPE_API_KEY not found in environment variables")
        print("\nPlease set it using:")
        print("  export DASHSCOPE_API_KEY='your_api_key_here'")
        sys.exit(1)
    
    try:
        # åˆ›å»ºåˆ†å‰²å™¨å¹¶å¤„ç†
        segmenter = Qwen3VLSegmentation()
        result = segmenter.process_page(
            pdf_path=pdf_path,
            page_number=page_number,
            output_dir=output_dir
        )
        
        # æ ¹æ®ç»“æœè®¾ç½®é€€å‡ºç 
        sys.exit(0 if result['success'] else 1)
        
    except Exception as e:
        print(f"\nâŒ Error: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
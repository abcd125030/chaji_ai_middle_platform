"""
Step1 æ™ºèƒ½æå–æµç¨‹æµ‹è¯•

æµ‹è¯• Step1 åŠå…¶æ ¸å¿ƒç»„ä»¶çš„å®Œæ•´æµç¨‹ï¼š
1. PageAnalyzer - é¡µé¢å…ƒç´ åˆ†æ
2. ExtractionStrategyDecider - ç­–ç•¥å†³ç­–
3. OCRHandler - OCRè¯†åˆ«ï¼ˆå¦‚éœ€è¦ï¼‰
4. TextExtractor - æ–‡æœ¬æå–å’Œæ ¼å¼åŒ–
5. è¾“å‡ºæ–‡ä»¶éªŒè¯
"""
import os
import json
import logging
from datetime import datetime
from pathlib import Path
from django.test import TestCase
from django.conf import settings

from webapps.toolkit.services.pdf_extractor.processors.step1_text_extractor import TextExtractor
from webapps.toolkit.services.pdf_extractor.processors.components import (
    PageAnalyzer,
    ExtractionStrategy,
    ExtractionStrategyDecider,
    OCRHandler
)


class Step1SmartExtractionTestCase(TestCase):
    """
    Step1 æ™ºèƒ½æå–æµ‹è¯•åŸºç±»

    éµå¾ª"åœ¨éš”ç¦»ç¯å¢ƒä¸­é‡å»ºçœŸå®çŠ¶æ€"çš„åŸåˆ™
    """

    def setUp(self):
        """
        åœ¨æ¯ä¸ªtest_æ–¹æ³•æ‰§è¡Œå‰è¿è¡Œ
        """
        # --- è¾“å‡ºç›®å½•è®¾ç½® ---
        self.output_dir = Path(settings.BASE_DIR) / 'webapps' / 'toolkit' / 'tests' / 'outputs'
        self.output_dir.mkdir(parents=True, exist_ok=True)

        # ä½¿ç”¨ç¬¦åˆè§„èŒƒçš„æ–‡ä»¶å‘½åæ ¼å¼
        test_method_name = self._testMethodName
        timestamp = datetime.now()
        date_str = timestamp.strftime('%Y%m%d')
        time_str = timestamp.strftime('%H%M%S')

        # ç”Ÿæˆç¬¦åˆè§„èŒƒçš„æ–‡ä»¶å
        self.process_filename = f'process-{date_str}-{time_str}-{test_method_name}.json'
        self.log_filename = f'log-{date_str}-{time_str}-{test_method_name}.log'
        self.result_filename = f'result-{date_str}-{time_str}-{test_method_name}.json'

        # è®¾ç½®æ—¥å¿—
        self.setup_logging()
        self.logger.info(f"Test method '{test_method_name}' starting...")

        # --- è¿‡ç¨‹æ•°æ®è®°å½• ---
        self.process_data = {
            "test_info": {
                "name": f"{self.__class__.__name__}.{test_method_name}",
                "start_time": datetime.now().isoformat()
            },
            "execution_steps": [],
            "page_results": []
        }

        # --- æµ‹è¯•PDFæ–‡ä»¶è·¯å¾„ ---
        self.test_pdf_path = Path(settings.BASE_DIR) / 'webapps' / 'toolkit' / 'tests' / '1ã€æœåŠ¡æ“ä½œæ‰‹å†Œ.pdf'

        if not self.test_pdf_path.exists():
            raise FileNotFoundError(f"æµ‹è¯•PDFæ–‡ä»¶ä¸å­˜åœ¨: {self.test_pdf_path}")

        self.logger.info(f"æµ‹è¯•PDFæ–‡ä»¶: {self.test_pdf_path}")

        # --- ä»PDFExtractorConfigè·å–APIä¿¡æ¯ ---
        from webapps.toolkit.services.pdf_extractor.config import PDFExtractorConfig

        self.api_key = PDFExtractorConfig.QWEN_API_KEY
        self.base_url = PDFExtractorConfig.QWEN_BASE_URL

        if not self.api_key:
            self.logger.warning("æœªé…ç½®DASHSCOPE_API_KEYï¼ŒOCRåŠŸèƒ½å°†è¢«ç¦ç”¨")
        else:
            self.logger.info(f"APIé…ç½®å·²åŠ è½½: base_url={self.base_url}")

    def setup_logging(self):
        """é…ç½®æ—¥å¿—è®°å½•å™¨"""
        log_file = self.output_dir / self.log_filename

        # é¿å…é‡å¤æ·»åŠ handler
        self.logger = logging.getLogger(self.log_filename)
        if not self.logger.handlers:
            self.logger.setLevel(logging.DEBUG)
            formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')

            # æ–‡ä»¶å¤„ç†å™¨
            fh = logging.FileHandler(log_file, encoding='utf-8')
            fh.setFormatter(formatter)
            self.logger.addHandler(fh)

            # æ§åˆ¶å°å¤„ç†å™¨
            sh = logging.StreamHandler()
            sh.setFormatter(formatter)
            self.logger.addHandler(sh)

    def record_step(self, action, input_data, output_data, **kwargs):
        """è®°å½•æ‰§è¡Œæ­¥éª¤"""
        step_number = len(self.process_data["execution_steps"]) + 1
        step_data = {
            "step": step_number,
            "action": action,
            "input": self._truncate_data(input_data, 500),
            "output": self._truncate_data(output_data, 500),
            "timestamp": datetime.now().isoformat(),
            **kwargs
        }
        self.process_data["execution_steps"].append(step_data)
        self.logger.info(f"Step {step_number}: {action} recorded.")

    def _truncate_data(self, data, max_length=500):
        """æˆªæ–­æ•°æ®ä»¥é¿å…è¿‡é•¿"""
        data_str = str(data)
        if len(data_str) > max_length:
            return data_str[:max_length] + "... (truncated)"
        return data_str

    def tearDown(self):
        """
        åœ¨æ¯ä¸ªtest_æ–¹æ³•æ‰§è¡Œåè¿è¡Œ
        """
        end_time = datetime.now()
        start_time_iso = self.process_data["test_info"]["start_time"]
        start_time = datetime.fromisoformat(start_time_iso)
        duration = (end_time - start_time).total_seconds()

        self.process_data["test_info"]["end_time"] = end_time.isoformat()
        self.process_data["test_info"]["duration"] = duration

        # ä¿å­˜è¿‡ç¨‹æ•°æ®
        process_file = self.output_dir / self.process_filename
        try:
            with open(process_file, 'w', encoding='utf-8') as f:
                json.dump(self.process_data, f, ensure_ascii=False, indent=2, default=str)
            self.logger.info(f"âœ“ è¿‡ç¨‹æ•°æ®å·²ä¿å­˜: {process_file}")
        except Exception as e:
            self.logger.error(f"Failed to write process file: {e}")

        self.logger.info(f"Test method finished. Duration: {duration:.2f}s")
        self.logger.info(f"ğŸ“ æµ‹è¯•è¾“å‡ºç›®å½•: {self.output_dir.absolute()}")
        print(f"\n[INFO] Test outputs saved to directory: {self.output_dir.absolute()}")


class TestStep1SmartExtraction(Step1SmartExtractionTestCase):
    """æµ‹è¯• Step1 æ™ºèƒ½æå–å®Œæ•´æµç¨‹"""

    def test_three_pages_smart_extraction(self):
        """
        æµ‹è¯•å‰3é¡µçš„æ™ºèƒ½æå–æµç¨‹

        æµ‹è¯•é¡µé¢ç‰¹ç‚¹ï¼š
        - ç¬¬1é¡µï¼šå°é¢é¡µï¼ˆæ–‡æœ¬ä¸°å¯Œï¼Œ156å­—ç¬¦ï¼‰
        - ç¬¬2é¡µï¼šå›¾ç‰‡é¡µï¼ˆçº¯å›¾ç‰‡ï¼Œ0æ–‡æœ¬ï¼‰
        - ç¬¬3é¡µï¼šå¤æ‚å›¾è¡¨é¡µï¼ˆ3514æ›²çº¿ï¼Œ187çŸ©å½¢ï¼‰

        éªŒè¯ç‚¹ï¼š
        1. æ¯é¡µéƒ½èƒ½æˆåŠŸåˆ†æå…ƒç´ 
        2. ç­–ç•¥å†³ç­–ç¬¦åˆé¢„æœŸ
        3. æ–‡æœ¬æå–æˆåŠŸ
        4. è¾“å‡ºæ–‡ä»¶å®Œæ•´
        5. æ–‡ä»¶å†…å®¹åˆç†
        """
        self.logger.info("=" * 70)
        self.logger.info("å¼€å§‹æµ‹è¯•: Step1 æ™ºèƒ½æå–æµç¨‹ï¼ˆå‰3é¡µï¼‰")
        self.logger.info("=" * 70)

        # ==================== åˆå§‹åŒ– TextExtractor ====================
        self.logger.info("åˆå§‹åŒ– TextExtractor...")

        extractor = TextExtractor(
            api_key=self.api_key,
            base_url=self.base_url,
            model="qwen-coder-plus",
            enable_smart_extraction=True,
            ocr_dpi=144
        )

        self.record_step(
            action="åˆå§‹åŒ–TextExtractor",
            input_data={
                "enable_smart_extraction": True,
                "ocr_dpi": 144,
                "has_api_config": bool(self.api_key and self.base_url)
            },
            output_data={
                "page_analyzer": extractor.page_analyzer is not None,
                "strategy_decider": extractor.strategy_decider is not None,
                "ocr_handler": extractor.ocr_handler is not None
            }
        )

        self.assertIsNotNone(extractor.page_analyzer, "PageAnalyzeråº”è¯¥è¢«åˆå§‹åŒ–")
        self.assertIsNotNone(extractor.strategy_decider, "ExtractionStrategyDecideråº”è¯¥è¢«åˆå§‹åŒ–")

        if self.api_key and self.base_url:
            self.assertIsNotNone(extractor.ocr_handler, "OCRHandleråº”è¯¥è¢«åˆå§‹åŒ–ï¼ˆæœ‰APIé…ç½®ï¼‰")

        self.logger.info("âœ… TextExtractoråˆå§‹åŒ–å®Œæˆ")

        # ==================== åˆ›å»ºæµ‹è¯•è¾“å‡ºç›®å½• ====================
        test_output_dir = self.output_dir / f"step1_test_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        test_output_dir.mkdir(parents=True, exist_ok=True)
        self.logger.info(f"æµ‹è¯•è¾“å‡ºç›®å½•: {test_output_dir}")

        # ==================== æµ‹è¯•å‰3é¡µ ====================
        pages_to_test = [1, 2, 3]
        expected_strategies = {
            1: ExtractionStrategy.DIRECT_TEXT,  # ç¬¬1é¡µï¼šæ–‡æœ¬ä¸°å¯Œï¼Œåº”è¯¥ç›´æ¥æå–
            2: ExtractionStrategy.OCR,          # ç¬¬2é¡µï¼šçº¯å›¾ç‰‡ï¼Œåº”è¯¥OCR
            3: ExtractionStrategy.OCR           # ç¬¬3é¡µï¼šå¤æ‚å›¾è¡¨ï¼Œåº”è¯¥OCR
        }

        for page_num in pages_to_test:
            self.logger.info("=" * 60)
            self.logger.info(f"æµ‹è¯•ç¬¬ {page_num} é¡µ")
            self.logger.info("=" * 60)

            page_output_dir = test_output_dir / f"page_{page_num}"
            page_output_dir.mkdir(parents=True, exist_ok=True)

            start_time = datetime.now()

            try:
                # æ‰§è¡Œæ™ºèƒ½æå–
                result = extractor.smart_extract_page(
                    pdf_path=str(self.test_pdf_path),
                    page_number=page_num,
                    output_dir=page_output_dir,
                    save_analysis=True,
                    save_page_image=True  # ä¿å­˜å›¾ç‰‡ä»¥ä¾¿å®¡æŸ¥
                )

                duration = (datetime.now() - start_time).total_seconds()

                # è®°å½•ç»“æœ
                page_result = {
                    "page_number": page_num,
                    "status": "success",
                    "duration": duration,
                    "extraction_method": result['extraction_method'],
                    "strategy": result['strategy_decision']['strategy'],
                    "confidence": result['strategy_decision']['confidence'],
                    "text_length": len(result['extracted_text']),
                    "output_files": result['output_files']
                }
                self.process_data["page_results"].append(page_result)

                self.logger.info(f"âœ“ ç¬¬{page_num}é¡µæå–å®Œæˆ")
                self.logger.info(f"  ç­–ç•¥: {result['strategy_decision']['strategy']}")
                self.logger.info(f"  ç½®ä¿¡åº¦: {result['strategy_decision']['confidence']:.2f}")
                self.logger.info(f"  æå–æ–¹æ³•: {result['extraction_method']}")
                self.logger.info(f"  æ–‡æœ¬é•¿åº¦: {len(result['extracted_text'])} å­—ç¬¦")
                self.logger.info(f"  è€—æ—¶: {duration:.2f}ç§’")

                # ==================== éªŒè¯åˆ†æç»“æœ ====================
                analysis = result['analysis_result']
                self.logger.info(f"  [åˆ†æ] æ–‡æœ¬é•¿åº¦: {analysis['pdfplumber_metrics']['text_length']}")
                self.logger.info(f"  [åˆ†æ] å•è¯æ•°: {analysis['pdfplumber_metrics']['word_count']}")
                self.logger.info(f"  [åˆ†æ] å›¾ç‰‡æ•°: {analysis['pdfplumber_metrics']['image_count']}")
                self.logger.info(f"  [åˆ†æ] è¡¨æ ¼æ•°: {analysis['pdfplumber_metrics']['table_count']}")
                self.logger.info(f"  [åˆ†æ] ç»˜å›¾å…ƒç´ : {analysis['pymupdf_metrics']['drawing_count']}")

                # éªŒè¯ç­–ç•¥å†³ç­–ï¼ˆå¦‚æœæœ‰æ˜ç¡®é¢„æœŸï¼‰
                if page_num in expected_strategies:
                    expected_strategy = expected_strategies[page_num]
                    actual_strategy_str = result['strategy_decision']['strategy']

                    self.logger.info(f"  [éªŒè¯] é¢„æœŸç­–ç•¥: {expected_strategy.value}")
                    self.logger.info(f"  [éªŒè¯] å®é™…ç­–ç•¥: {actual_strategy_str}")

                    # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ä¸å¼ºåˆ¶æ–­è¨€ç­–ç•¥å¿…é¡»å®Œå…¨ä¸€è‡´
                    # å› ä¸ºç­–ç•¥å†³ç­–å™¨å¯èƒ½æ ¹æ®å®é™…æƒ…å†µåšè°ƒæ•´
                    # æˆ‘ä»¬åªè®°å½•æ˜¯å¦ç¬¦åˆé¢„æœŸ
                    if actual_strategy_str == expected_strategy.value:
                        self.logger.info(f"  âœ“ ç­–ç•¥ç¬¦åˆé¢„æœŸ")
                    else:
                        self.logger.warning(f"  âš  ç­–ç•¥ä¸é¢„æœŸä¸åŒï¼ˆè¿™å¯èƒ½æ˜¯æ­£å¸¸çš„ï¼‰")

                # ==================== éªŒè¯è¾“å‡ºæ–‡ä»¶ ====================
                self.logger.info(f"  [éªŒè¯] æ£€æŸ¥è¾“å‡ºæ–‡ä»¶...")

                output_files = result['output_files']

                # éªŒè¯æœ€ç»ˆmarkdown
                final_md_path = Path(output_files['final_md'])
                self.assertTrue(final_md_path.exists(), f"æœ€ç»ˆmarkdownåº”è¯¥å­˜åœ¨: {final_md_path}")
                self.assertGreater(final_md_path.stat().st_size, 0, "æœ€ç»ˆmarkdownä¸åº”ä¸ºç©º")
                self.logger.info(f"    âœ“ æœ€ç»ˆmarkdown: {final_md_path.name} ({final_md_path.stat().st_size} å­—èŠ‚)")

                # éªŒè¯æå–æ–‡æœ¬
                extracted_text_path = Path(output_files['extracted_text'])
                self.assertTrue(extracted_text_path.exists(), f"æå–æ–‡æœ¬åº”è¯¥å­˜åœ¨: {extracted_text_path}")
                self.logger.info(f"    âœ“ æå–æ–‡æœ¬: {extracted_text_path.name}")

                # éªŒè¯åˆ†ææ–‡ä»¶
                if output_files.get('analysis'):
                    analysis_path = Path(output_files['analysis'])
                    self.assertTrue(analysis_path.exists(), f"åˆ†ææ–‡ä»¶åº”è¯¥å­˜åœ¨: {analysis_path}")
                    self.logger.info(f"    âœ“ åˆ†ææ–‡ä»¶: {analysis_path.name}")

                # éªŒè¯ç­–ç•¥æ–‡ä»¶
                if output_files.get('strategy'):
                    strategy_path = Path(output_files['strategy'])
                    self.assertTrue(strategy_path.exists(), f"ç­–ç•¥æ–‡ä»¶åº”è¯¥å­˜åœ¨: {strategy_path}")
                    self.logger.info(f"    âœ“ ç­–ç•¥æ–‡ä»¶: {strategy_path.name}")

                # éªŒè¯OCRè°ƒè¯•æ–‡ä»¶ï¼ˆå¦‚æœä½¿ç”¨äº†OCRï¼‰
                if output_files.get('ocr_debug'):
                    ocr_debug_path = Path(output_files['ocr_debug'])
                    self.assertTrue(ocr_debug_path.exists(), f"OCRè°ƒè¯•æ–‡ä»¶åº”è¯¥å­˜åœ¨: {ocr_debug_path}")
                    self.logger.info(f"    âœ“ OCRè°ƒè¯•æ–‡ä»¶: {ocr_debug_path.name}")

                # éªŒè¯é¡µé¢å›¾ç‰‡ï¼ˆå¦‚æœä¿å­˜äº†ï¼‰
                if output_files.get('page_image'):
                    page_image_path = Path(output_files['page_image'])
                    self.assertTrue(page_image_path.exists(), f"é¡µé¢å›¾ç‰‡åº”è¯¥å­˜åœ¨: {page_image_path}")
                    self.logger.info(f"    âœ“ é¡µé¢å›¾ç‰‡: {page_image_path.name}")

                self.logger.info(f"âœ… ç¬¬{page_num}é¡µæ‰€æœ‰éªŒè¯é€šè¿‡")

            except Exception as e:
                duration = (datetime.now() - start_time).total_seconds()
                self.logger.error(f"âŒ ç¬¬{page_num}é¡µæå–å¤±è´¥: {str(e)}", exc_info=True)

                page_result = {
                    "page_number": page_num,
                    "status": "failed",
                    "duration": duration,
                    "error": str(e)
                }
                self.process_data["page_results"].append(page_result)

                # å¤±è´¥æ—¶ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œç»§ç»­æµ‹è¯•ä¸‹ä¸€é¡µ
                continue

        # ==================== ä¿å­˜æµ‹è¯•ç»“æœ ====================
        self.logger.info("=" * 70)
        self.logger.info("ç”Ÿæˆæµ‹è¯•ç»“æœæŠ¥å‘Š...")
        self.logger.info("=" * 70)

        successful_pages = [r for r in self.process_data["page_results"] if r["status"] == "success"]
        failed_pages = [r for r in self.process_data["page_results"] if r["status"] == "failed"]

        test_result = {
            "test_name": "test_three_pages_smart_extraction",
            "pdf_file": str(self.test_pdf_path),
            "pages_tested": pages_to_test,
            "total_pages": len(pages_to_test),
            "successful_pages": len(successful_pages),
            "failed_pages": len(failed_pages),
            "success_rate": len(successful_pages) / len(pages_to_test) * 100,
            "test_output_dir": str(test_output_dir),
            "page_results": self.process_data["page_results"]
        }

        result_file = self.output_dir / self.result_filename
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(test_result, f, ensure_ascii=False, indent=2, default=str)

        self.logger.info("=" * 70)
        self.logger.info("âœ… æµ‹è¯•å®Œæˆ")
        self.logger.info(f"æˆåŠŸ: {len(successful_pages)}/{len(pages_to_test)} é¡µ")
        self.logger.info(f"å¤±è´¥: {len(failed_pages)}/{len(pages_to_test)} é¡µ")
        self.logger.info(f"æˆåŠŸç‡: {test_result['success_rate']:.1f}%")
        self.logger.info(f"ğŸ“ è¾“å‡ºç›®å½•: {test_output_dir}")
        self.logger.info(f"ğŸ“Š æµ‹è¯•æŠ¥å‘Š: {result_file}")
        self.logger.info("=" * 70)

        # æ–­è¨€ï¼šè‡³å°‘æœ‰ä¸€é¡µæˆåŠŸ
        self.assertGreater(len(successful_pages), 0, "è‡³å°‘åº”è¯¥æœ‰ä¸€é¡µæå–æˆåŠŸ")
